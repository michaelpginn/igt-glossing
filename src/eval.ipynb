{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-16T02:45:26.886612Z",
     "start_time": "2023-12-16T02:45:02.606472Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07ba0e9a790f499e99e2c9b1d293d702",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9774 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f170cfffc7114484863304b5c592287d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/232 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a3f286eccdc470d9ab62beef5b2d5cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/633 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "import random\n",
    "from datasets import DatasetDict\n",
    "from transformers import RobertaConfig, RobertaForTokenClassification, TrainingArguments, Trainer\n",
    "from data_handling import load_data_file, create_vocab, create_gloss_vocab, prepare_dataset\n",
    "from uspanteko_morphology import morphology\n",
    "from tokenizer import WordLevelTokenizer\n",
    "from taxonomic_loss_model import TaxonomicLossModel\n",
    "from eval import eval_accuracy\n",
    "\n",
    "MODEL_INPUT_LENGTH = 64\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "random.seed(1)\n",
    "\n",
    "train_data = load_data_file('../data/usp-train-track2-uncovered')\n",
    "dev_data = load_data_file('../data/usp-dev-track2-uncovered')\n",
    "test_data = load_data_file('../data/usp-test-track2-uncovered')\n",
    "\n",
    "train_vocab = create_vocab([line.morphemes() for line in train_data], threshold=1)\n",
    "tokenizer = WordLevelTokenizer(vocab=train_vocab, model_max_length=MODEL_INPUT_LENGTH)\n",
    "\n",
    "glosses = create_gloss_vocab(morphology)\n",
    "\n",
    "dataset = DatasetDict()\n",
    "\n",
    "dataset['train'] = prepare_dataset(data=train_data, tokenizer=tokenizer, labels=glosses, device='mps')\n",
    "dataset['dev'] = prepare_dataset(data=dev_data, tokenizer=tokenizer, labels=glosses, device='mps')\n",
    "dataset['test'] = prepare_dataset(data=test_data, tokenizer=tokenizer, labels=glosses, device='mps')\n",
    "\n",
    "config = RobertaConfig(\n",
    "    vocab_size=tokenizer.vocab_size,\n",
    "    max_position_embeddings=MODEL_INPUT_LENGTH,\n",
    "    pad_token_id=tokenizer.PAD_ID,\n",
    "    position_embedding_type='absolute',\n",
    "    num_labels=len(glosses)\n",
    ")\n",
    "\n",
    "flat_model = RobertaForTokenClassification.from_pretrained(\"../models/full-flat-1\").to('mps')\n",
    "tax_model = TaxonomicLossModel.from_pretrained(\"../models/full-tax_loss-1 (alt)\", loss_sum='linear').to('mps')\n",
    "tax_model.use_morphology_tree(morphology, max_depth=5)\n",
    "harmonic_model = TaxonomicLossModel.from_pretrained(\"../models/full-harmonic_loss-1 (alt)\", loss_sum='harmonic').to(\n",
    "    'mps')\n",
    "harmonic_model.use_morphology_tree(morphology, max_depth=5)\n",
    "\n",
    "hierarchy_matrix = tax_model.hierarchy_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-16T02:45:29.000414Z",
     "start_time": "2023-12-16T02:45:26.890636Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 1/10 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDS [[61  1 25 ... 39 39 39]\n",
      " [25 38  1 ... 39 39 39]\n",
      " [61  1 25 ... 43 43 43]\n",
      " ...\n",
      " [54  1 26 ... 43 43 43]\n",
      " [54  1 26 ... 39 39 39]\n",
      " [55  1 60 ... 38 38 38]]\n",
      "LABELS [[  61    1   25 ... -100 -100 -100]\n",
      " [  25   38    1 ... -100 -100 -100]\n",
      " [  61    1   25 ... -100 -100 -100]\n",
      " ...\n",
      " [  54    1   26 ... -100 -100 -100]\n",
      " [  54    1   26 ... -100 -100 -100]\n",
      " [  60    1   60 ... -100 -100 -100]]\n",
      "(633, 64)\n",
      "Preds:\t ['CONJ', '[SEP]', 'COM', 'VI', '[SEP]', 'S', '[SEP]', 'DIM', '[SEP]', 'S', '[SEP]', 'E3', 'SREL', '[SEP]', 'E3', 'S']\n",
      "Labels:\t ['CONJ', '[SEP]', 'COM', 'VI', '[SEP]', 'VT', '[SEP]', 'DIM', '[SEP]', 'S', '[SEP]', 'E3S', 'SREL', '[SEP]', 'E3S', 'S']\n",
      "PRED CATEGORIES [47.0, 1.0, 15.0, 24.0, 1.0, 29.0, 1.0, 34.0, 1.0, 29.0, 1.0, 4.0, 44.0, 1.0, 4.0, 29.0]\n",
      "TRUE CATEGORIES [47.0, 1.0, 15.0, 24.0, 1.0, 25.0, 1.0, 34.0, 1.0, 29.0, 1.0, 3.0, 44.0, 1.0, 3.0, 29.0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.11494144797325134,\n",
       " 'eval_accuracy': {'average_accuracy': 0.7371333708419027,\n",
       "  'accuracy': 0.7410688768219491},\n",
       " 'eval_f1': 0.491565613887541,\n",
       " 'eval_category_accuracy': 0.8283058243217606,\n",
       " 'eval_category_f1': 0.5964630122531189,\n",
       " 'eval_runtime': 2.0843,\n",
       " 'eval_samples_per_second': 303.697,\n",
       " 'eval_steps_per_second': 4.798}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_trainer(model: RobertaForTokenClassification, dataset: DatasetDict, tokenizer: WordLevelTokenizer,\n",
    "                   labels, batch_size, max_epochs):\n",
    "    def compute_metrics(eval_preds):\n",
    "        preds, gold_labels = eval_preds\n",
    "        if isinstance(preds, tuple):\n",
    "            preds = preds[0]\n",
    "\n",
    "        print(\"PREDS\", preds)\n",
    "        print(\"LABELS\", gold_labels)\n",
    "        if len(gold_labels.shape) > 2:\n",
    "            gold_labels = gold_labels.take(axis=1, indices=0)\n",
    "\n",
    "        print(gold_labels.shape)\n",
    "\n",
    "        # Decode predicted output\n",
    "        decoded_preds = [[labels[index] for index in pred_seq if len(labels) > index >= 0] for pred_seq in preds]\n",
    "\n",
    "        # Decode (gold) labels\n",
    "        decoded_labels = [[labels[index] for index in label_seq if len(labels) > index >= 0] for label_seq in\n",
    "                          gold_labels]\n",
    "\n",
    "        # Trim preds to the same length as the labels\n",
    "        decoded_preds = [pred_seq[:len(label_seq)] for pred_seq, label_seq in zip(decoded_preds, decoded_labels)]\n",
    "\n",
    "        print('Preds:\\t', decoded_preds[0])\n",
    "        print('Labels:\\t', decoded_labels[0])\n",
    "\n",
    "        accuracy = eval_accuracy(decoded_preds, decoded_labels)\n",
    "\n",
    "        # Calculate f1 between decoded_preds and decoded_labels\n",
    "        flat_true_labels = [label for sublist in decoded_labels for label in sublist]\n",
    "        flat_predicted_labels = [label for sublist in decoded_preds for label in sublist]\n",
    "\n",
    "        # Compute F1 score\n",
    "        f1 = f1_score(flat_true_labels, flat_predicted_labels, average='macro')\n",
    "\n",
    "        # Compute accuracy at the second level of hierarchy_matrix\n",
    "        def compute_list_of_lists_accuracy(true_labels, predicted_labels):\n",
    "            correct = 0\n",
    "            total = 0\n",
    "\n",
    "            for t_list, p_list in zip(true_labels, predicted_labels):\n",
    "                # Count matches in the overlapping parts\n",
    "                correct += sum(t == p for t, p in zip(t_list, p_list))\n",
    "                # Total is the length of the true list (since missing predictions are errors)\n",
    "                total += len(t_list)\n",
    "\n",
    "            return correct / total if total > 0 else 0\n",
    "\n",
    "        pred_indices = [[index for index in pred_seq if len(labels) > index >= 0] for pred_seq in preds]\n",
    "        true_indices = [[index for index in label_seq if len(labels) > index >= 0] for label_seq in gold_labels]\n",
    "        pred_indices = [pred_seq[:len(label_seq)] for pred_seq, label_seq in zip(pred_indices, true_indices)]\n",
    "        pred_categories = [[hierarchy_matrix[2][index] for index in pred_seq] for pred_seq in pred_indices]\n",
    "        true_categories = [[hierarchy_matrix[2][index] for index in gold_labels] for gold_labels in true_indices]\n",
    "        flat_pred_categories = [label for sublist in pred_categories for label in sublist]\n",
    "        flat_true_categories = [label for sublist in true_categories for label in sublist]\n",
    "\n",
    "        print(\"PRED CATEGORIES\", pred_categories[0])\n",
    "        print(\"TRUE CATEGORIES\", true_categories[0])\n",
    "\n",
    "        # Compute accuracy between two lists\n",
    "        category_accuracy = compute_list_of_lists_accuracy(true_categories, pred_categories)\n",
    "\n",
    "        category_f1 = f1_score(flat_true_categories, flat_pred_categories, average='macro')\n",
    "\n",
    "        return {\n",
    "            \"accuracy\": accuracy,\n",
    "            \"f1\": f1,\n",
    "            \"category_accuracy\": category_accuracy,\n",
    "            \"category_f1\": category_f1\n",
    "        }\n",
    "\n",
    "    def preprocess_logits_for_metrics(logits, labels):\n",
    "        return logits.argmax(dim=2)\n",
    "\n",
    "    args = TrainingArguments(\n",
    "        output_dir=f\"../finetune-training-checkpoints\",\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        gradient_accumulation_steps=3,\n",
    "        save_strategy=\"epoch\",\n",
    "        save_total_limit=3,\n",
    "        num_train_epochs=max_epochs,\n",
    "        load_best_model_at_end=True,\n",
    "        logging_strategy='epoch',\n",
    "    )\n",
    "\n",
    "    return Trainer(\n",
    "        model,\n",
    "        args,\n",
    "        train_dataset=dataset[\"train\"],\n",
    "        eval_dataset=dataset[\"test\"],\n",
    "        compute_metrics=compute_metrics,\n",
    "        preprocess_logits_for_metrics=preprocess_logits_for_metrics,\n",
    "    )\n",
    "\n",
    "\n",
    "flat_trainer = create_trainer(flat_model, dataset=dataset, tokenizer=tokenizer, labels=glosses, batch_size=BATCH_SIZE,\n",
    "                              max_epochs=100)\n",
    "tax_trainer = create_trainer(tax_model, dataset=dataset, tokenizer=tokenizer, labels=glosses, batch_size=BATCH_SIZE,\n",
    "                             max_epochs=100)\n",
    "harmonic_trainer = create_trainer(harmonic_model, dataset=dataset, tokenizer=tokenizer, labels=glosses,\n",
    "                                  batch_size=BATCH_SIZE,\n",
    "                                  max_epochs=100)\n",
    "\n",
    "flat_trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-16T02:43:26.562794Z",
     "start_time": "2023-12-16T02:43:23.742434Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 1/10 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDS [[61  1 25 ... 39 39 39]\n",
      " [25 38  1 ... 39 39 39]\n",
      " [61  1 25 ... 39 39 39]\n",
      " ...\n",
      " [54  1 26 ... 39 39 39]\n",
      " [54  1 26 ... 39 39 39]\n",
      " [60  1 60 ... 43 43 43]]\n",
      "LABELS [[61  1 25 ... 66 66 66]\n",
      " [25 38  1 ... 66 66 66]\n",
      " [61  1 25 ... 66 66 66]\n",
      " ...\n",
      " [54  1 26 ... 66 66 66]\n",
      " [54  1 26 ... 66 66 66]\n",
      " [60  1 60 ... 66 66 66]]\n",
      "(633, 64)\n",
      "Preds:\t ['CONJ', '[SEP]', 'COM', 'VI', '[SEP]', 'S', '[SEP]', 'DIM', '[SEP]', 'S', '[SEP]', 'E3S', 'SREL', '[SEP]', 'E3S', 'S']\n",
      "Labels:\t ['CONJ', '[SEP]', 'COM', 'VI', '[SEP]', 'VT', '[SEP]', 'DIM', '[SEP]', 'S', '[SEP]', 'E3S', 'SREL', '[SEP]', 'E3S', 'S']\n",
      "PRED CATEGORIES [47.0, 1.0, 15.0, 24.0, 1.0, 29.0, 1.0, 34.0, 1.0, 29.0, 1.0, 3.0, 44.0, 1.0, 3.0, 29.0]\n",
      "TRUE CATEGORIES [47.0, 1.0, 15.0, 24.0, 1.0, 25.0, 1.0, 34.0, 1.0, 29.0, 1.0, 3.0, 44.0, 1.0, 3.0, 29.0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.20068112015724182,\n",
       " 'eval_accuracy': {'average_accuracy': 0.8610567136041077,\n",
       "  'accuracy': 0.8673906830523006},\n",
       " 'eval_f1': 0.6621791917978597,\n",
       " 'eval_category_accuracy': 0.9182318345664959,\n",
       " 'eval_category_f1': 0.7377983066869656,\n",
       " 'eval_runtime': 2.8114,\n",
       " 'eval_samples_per_second': 225.158,\n",
       " 'eval_steps_per_second': 3.557}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tax_trainer.evaluate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-16T02:45:31.584766Z",
     "start_time": "2023-12-16T02:45:29.001088Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 1/10 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDS [[61  1 25 ... 43 43 43]\n",
      " [25 38  1 ... 43 43 43]\n",
      " [61  1 25 ... 43 43 43]\n",
      " ...\n",
      " [54  1 26 ... 43 43 43]\n",
      " [54  1 26 ... 43 43 43]\n",
      " [60  1 60 ... 43 43 43]]\n",
      "LABELS [[61  1 25 ... 66 66 66]\n",
      " [25 38  1 ... 66 66 66]\n",
      " [61  1 25 ... 66 66 66]\n",
      " ...\n",
      " [54  1 26 ... 66 66 66]\n",
      " [54  1 26 ... 66 66 66]\n",
      " [60  1 60 ... 66 66 66]]\n",
      "(633, 64)\n",
      "Preds:\t ['CONJ', '[SEP]', 'COM', 'VI', '[SEP]', 'S', '[SEP]', 'DIM', '[SEP]', 'S', '[SEP]', 'E3S', 'SREL', '[SEP]', 'E3S', 'S']\n",
      "Labels:\t ['CONJ', '[SEP]', 'COM', 'VI', '[SEP]', 'VT', '[SEP]', 'DIM', '[SEP]', 'S', '[SEP]', 'E3S', 'SREL', '[SEP]', 'E3S', 'S']\n",
      "PRED CATEGORIES [47.0, 1.0, 15.0, 24.0, 1.0, 29.0, 1.0, 34.0, 1.0, 29.0, 1.0, 3.0, 44.0, 1.0, 3.0, 29.0]\n",
      "TRUE CATEGORIES [47.0, 1.0, 15.0, 24.0, 1.0, 25.0, 1.0, 34.0, 1.0, 29.0, 1.0, 3.0, 44.0, 1.0, 3.0, 29.0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.1058390811085701,\n",
       " 'eval_accuracy': {'average_accuracy': 0.826985117743412,\n",
       "  'accuracy': 0.852529294084024},\n",
       " 'eval_f1': 0.6349280903489274,\n",
       " 'eval_category_accuracy': 0.907987099222159,\n",
       " 'eval_category_f1': 0.6897642733988156,\n",
       " 'eval_runtime': 2.5751,\n",
       " 'eval_samples_per_second': 245.817,\n",
       " 'eval_steps_per_second': 3.883}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "harmonic_trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-15T23:51:41.807474Z",
     "start_time": "2023-12-15T23:51:41.772614Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>7.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>61.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>8.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>62.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>8.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>8.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>9.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1     2     3     4\n",
       "0   0.0   0.0   0.0   0.0   0.0\n",
       "1   1.0   1.0   1.0   1.0   1.0\n",
       "2   2.0   2.0   2.0   2.0   2.0\n",
       "3   2.0   2.0   2.0   2.0   3.0\n",
       "4   2.0   2.0   2.0   3.0   4.0\n",
       "..  ...   ...   ...   ...   ...\n",
       "61  7.0  19.0  46.0  53.0  61.0\n",
       "62  8.0  20.0  47.0  54.0  62.0\n",
       "63  8.0  21.0  48.0  55.0  63.0\n",
       "64  8.0  22.0  49.0  56.0  64.0\n",
       "65  9.0  23.0  50.0  57.0  65.0\n",
       "\n",
       "[66 rows x 5 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hierarchy_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-15T23:50:08.595795Z",
     "start_time": "2023-12-15T23:50:08.551324Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-16T00:00:41.487421Z",
     "start_time": "2023-12-16T00:00:41.467376Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hierarchy_matrix[2][61]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-16T01:42:26.667100Z",
     "start_time": "2023-12-16T01:42:26.645090Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87860802"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "model_parameters = filter(lambda p: p.requires_grad, flat_model.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
