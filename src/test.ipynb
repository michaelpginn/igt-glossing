{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 10099 train lines and 1334 eval lines\n"
     ]
    }
   ],
   "source": [
    "from data import load_data_file, create_vocab\n",
    "\n",
    "train_data = load_data_file(\"../data/GenBench/story_advice_personal\")\n",
    "eval_data = load_data_file(\"../data/GenBench/history\")\n",
    "\n",
    "print(f\"Loaded {len(train_data)} train lines and {len(eval_data)} eval lines\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-25T01:14:33.583269Z",
     "start_time": "2023-08-25T01:14:33.051872Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from tokenizer import WordLevelTokenizer\n",
    "\n",
    "train_vocab = create_vocab([line.morphemes() for line in train_data], threshold=1)\n",
    "tokenizer = WordLevelTokenizer(vocab=train_vocab, model_max_length=64)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-25T01:14:33.641005Z",
     "start_time": "2023-08-25T01:14:33.639562Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/10099 [00:00<?, ?ex/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4e2bd22a79d443ec91ac5936b503d3d5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1334 [00:00<?, ?ex/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b7b149c3ed9b42d1a3bd72d73bfd12f1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from data import prepare_dataset, create_gloss_vocab\n",
    "from uspanteko_morphology import morphology as morphology_tree\n",
    "\n",
    "glosses = create_gloss_vocab(morphology_tree)\n",
    "train = prepare_dataset(data=train_data, tokenizer=tokenizer, labels=glosses, device=\"cpu\")\n",
    "eval = prepare_dataset(data=eval_data, tokenizer=tokenizer, labels=glosses, device=\"cpu\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-25T03:03:23.394228Z",
     "start_time": "2023-08-25T03:03:20.084378Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at michaelginn/uspanteko-mlm-large were not used when initializing DenoisedModel: ['lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias']\n",
      "- This IS expected if you are initializing DenoisedModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DenoisedModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DenoisedModel were not initialized from the model checkpoint at michaelginn/uspanteko-mlm-large and are newly initialized: ['denoiser.roberta.encoder.layer.0.attention.self.key.weight', 'denoiser.roberta.encoder.layer.0.attention.self.value.weight', 'denoiser.roberta.encoder.layer.2.attention.self.value.weight', 'denoiser.roberta.encoder.layer.0.intermediate.dense.bias', 'denoiser.roberta.encoder.layer.2.output.LayerNorm.bias', 'denoiser.roberta.encoder.layer.1.intermediate.dense.weight', 'denoiser.roberta.encoder.layer.1.attention.self.key.weight', 'denoiser.roberta.encoder.layer.0.attention.self.query.bias', 'denoiser.roberta.encoder.layer.1.output.dense.weight', 'denoiser.roberta.encoder.layer.2.output.dense.bias', 'denoiser.roberta.encoder.layer.1.attention.output.LayerNorm.weight', 'denoiser.roberta.encoder.layer.0.intermediate.dense.weight', 'classifier.weight', 'denoiser.lm_head.decoder.weight', 'denoiser.roberta.encoder.layer.1.output.LayerNorm.weight', 'denoiser.lm_head.bias', 'denoiser.roberta.encoder.layer.0.attention.self.key.bias', 'denoiser.roberta.encoder.layer.2.intermediate.dense.bias', 'denoiser.roberta.encoder.layer.2.output.dense.weight', 'denoiser.roberta.encoder.layer.1.attention.self.key.bias', 'denoiser.roberta.encoder.layer.0.attention.output.LayerNorm.bias', 'denoiser.roberta.encoder.layer.0.output.dense.bias', 'denoiser.roberta.encoder.layer.2.attention.self.query.bias', 'denoiser.roberta.encoder.layer.1.attention.self.value.weight', 'denoiser.roberta.encoder.layer.2.intermediate.dense.weight', 'denoiser.lm_head.layer_norm.weight', 'denoiser.lm_head.decoder.bias', 'denoiser.roberta.encoder.layer.1.output.LayerNorm.bias', 'denoiser.roberta.encoder.layer.0.output.dense.weight', 'denoiser.roberta.encoder.layer.0.attention.self.value.bias', 'denoiser.lm_head.dense.weight', 'denoiser.roberta.encoder.layer.1.attention.self.query.weight', 'denoiser.roberta.encoder.layer.2.attention.self.query.weight', 'denoiser.roberta.embeddings.LayerNorm.weight', 'denoiser.roberta.encoder.layer.0.attention.self.query.weight', 'denoiser.roberta.encoder.layer.1.attention.self.value.bias', 'denoiser.roberta.encoder.layer.0.attention.output.LayerNorm.weight', 'denoiser.roberta.encoder.layer.1.attention.self.query.bias', 'denoiser.roberta.encoder.layer.0.output.LayerNorm.bias', 'denoiser.roberta.encoder.layer.2.output.LayerNorm.weight', 'denoiser.roberta.encoder.layer.1.attention.output.LayerNorm.bias', 'denoiser.roberta.encoder.layer.2.attention.self.value.bias', 'denoiser.roberta.embeddings.LayerNorm.bias', 'denoiser.roberta.encoder.layer.2.attention.output.dense.bias', 'denoiser.roberta.encoder.layer.2.attention.output.LayerNorm.bias', 'denoiser.roberta.encoder.layer.2.attention.self.key.bias', 'denoiser.roberta.encoder.layer.1.output.dense.bias', 'denoiser.roberta.encoder.layer.2.attention.output.LayerNorm.weight', 'denoiser.roberta.embeddings.word_embeddings.weight', 'denoiser.roberta.embeddings.token_type_embeddings.weight', 'denoiser.lm_head.layer_norm.bias', 'denoiser.lm_head.dense.bias', 'denoiser.roberta.encoder.layer.1.attention.output.dense.weight', 'denoiser.roberta.encoder.layer.0.attention.output.dense.bias', 'denoiser.roberta.encoder.layer.0.output.LayerNorm.weight', 'denoiser.roberta.encoder.layer.2.attention.output.dense.weight', 'denoiser.roberta.encoder.layer.1.intermediate.dense.bias', 'denoiser.roberta.embeddings.position_embeddings.weight', 'denoiser.roberta.encoder.layer.1.attention.output.dense.bias', 'denoiser.roberta.encoder.layer.0.attention.output.dense.weight', 'classifier.bias', 'denoiser.roberta.encoder.layer.2.attention.self.key.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from denoised_model import DenoisedModel\n",
    "\n",
    "model = DenoisedModel.from_pretrained(\"michaelginn/uspanteko-mlm-large\", num_labels=len(glosses))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-25T01:14:39.933640Z",
     "start_time": "2023-08-25T01:14:39.064079Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "out = model.forward(input_ids=torch.LongTensor(eval['input_ids']),\n",
    "                    attention_mask=torch.LongTensor(eval['attention_mask']))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-25T03:33:16.044021Z",
     "start_time": "2023-08-25T03:33:13.411257Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "outputs": [],
   "source": [
    "preds = out.logits.max(-1).indices\n",
    "preds = preds.narrow(1, 0, 60)\n",
    "preds.size()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-25T03:50:45.453890Z",
     "start_time": "2023-08-25T03:50:45.442217Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [],
   "source": [
    "from transformers import AutoModelForMaskedLM\n",
    "\n",
    "denoiser = AutoModelForMaskedLM.from_pretrained(\"michaelginn/usp-gloss-denoiser\")\n",
    "\n",
    "attention_mask = (preds != 2).long()\n",
    "denoised_out = denoiser.forward(input_ids=preds, attention_mask=attention_mask)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-25T03:37:21.321932Z",
     "start_time": "2023-08-25T03:37:17.383807Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[-3.3836e+00, -5.1023e-01, -1.0617e+01,  ..., -1.3619e-01,\n           1.2214e+00,  1.1689e+00],\n         [-3.3444e+00,  5.2346e+00, -8.8257e+00,  ...,  5.2330e-01,\n          -3.1739e+00,  2.3671e+00],\n         [-3.3963e+00,  3.9592e+00, -9.6772e+00,  ..., -1.2468e+00,\n          -1.4130e+00,  1.1068e+00],\n         ...,\n         [-2.7051e+00,  4.3314e+00, -6.7782e+00,  ..., -6.9547e-01,\n          -1.8088e+00,  1.3990e+00],\n         [-2.4877e+00,  4.3198e+00, -6.3919e+00,  ..., -7.3392e-01,\n          -1.9627e+00,  1.5051e+00],\n         [-2.8166e+00,  4.1541e+00, -7.2809e+00,  ..., -1.0397e+00,\n          -1.8851e+00,  1.4013e+00]],\n\n        [[-2.8004e+00, -1.2937e-01, -7.9537e+00,  ..., -5.4015e-01,\n           9.1588e-01,  1.3190e+00],\n         [-3.4990e+00,  7.8989e+00, -9.1389e+00,  ..., -8.5067e-01,\n          -3.6493e+00,  1.0768e-02],\n         [-3.0368e+00,  3.7025e+00, -8.9272e+00,  ..., -1.8987e+00,\n          -1.3557e+00,  3.4993e-01],\n         ...,\n         [-2.7095e+00,  4.3989e+00, -6.7865e+00,  ..., -7.2100e-01,\n          -1.8220e+00,  1.3635e+00],\n         [-2.5063e+00,  4.3037e+00, -6.4692e+00,  ..., -7.6344e-01,\n          -1.9620e+00,  1.5050e+00],\n         [-2.7886e+00,  4.2309e+00, -7.1681e+00,  ..., -1.1392e+00,\n          -1.8711e+00,  1.2485e+00]],\n\n        [[-3.0132e+00, -7.3449e-01, -9.0341e+00,  ..., -5.7313e-02,\n           5.2846e-01,  3.2286e-01],\n         [-4.0373e+00,  8.3568e+00, -1.0412e+01,  ..., -1.1855e+00,\n          -3.3578e+00, -7.6145e-01],\n         [-2.7360e+00,  2.0876e+00, -8.0397e+00,  ...,  7.3047e-01,\n          -1.3260e+00,  2.0877e+00],\n         ...,\n         [-2.4668e+00,  2.9793e+00, -6.1862e+00,  ...,  1.7785e+00,\n          -1.4036e+00,  1.3143e+00],\n         [-2.3604e+00,  2.9841e+00, -6.1845e+00,  ...,  1.6683e+00,\n          -1.6481e+00,  1.4100e+00],\n         [-2.6497e+00,  2.9746e+00, -7.0946e+00,  ...,  1.3365e+00,\n          -1.6165e+00,  1.2896e+00]],\n\n        ...,\n\n        [[-3.8905e+00,  1.5446e+00, -1.1776e+01,  ...,  1.4690e+00,\n          -1.2491e+00,  2.8622e+00],\n         [-4.0911e+00,  7.6832e+00, -1.0967e+01,  ..., -3.1031e-01,\n          -3.0964e+00,  8.8400e-01],\n         [-4.0584e+00,  2.0564e+00, -1.1646e+01,  ...,  2.6971e+00,\n          -2.1500e+00,  4.8084e+00],\n         ...,\n         [-4.0434e+00,  4.8599e+00, -1.0008e+01,  ..., -8.8152e-02,\n          -2.7204e+00,  9.0654e-01],\n         [-3.8289e+00,  4.8885e+00, -9.6379e+00,  ..., -1.1292e-01,\n          -2.8815e+00,  8.8626e-01],\n         [-4.2569e+00,  4.6654e+00, -1.1062e+01,  ..., -1.6181e-01,\n          -2.9867e+00,  1.1544e+00]],\n\n        [[-2.0354e+00, -1.5041e+00, -5.9764e+00,  ...,  1.5374e+00,\n           3.1664e-01,  1.5896e+00],\n         [-4.3778e+00,  7.6563e+00, -1.2549e+01,  ..., -5.0663e-01,\n          -3.1780e+00, -5.4613e-02],\n         [-4.3752e+00,  1.8318e+00, -1.3972e+01,  ...,  1.5003e+00,\n          -6.4218e-01,  2.7685e+00],\n         ...,\n         [-4.0179e+00,  4.8972e+00, -9.9458e+00,  ..., -1.4016e-01,\n          -2.7267e+00,  8.6517e-01],\n         [-3.8033e+00,  4.9359e+00, -9.6063e+00,  ..., -1.5652e-01,\n          -2.8884e+00,  8.4420e-01],\n         [-4.2126e+00,  4.5991e+00, -1.0935e+01,  ..., -3.4898e-01,\n          -2.9665e+00,  9.6923e-01]],\n\n        [[-3.0288e+00, -1.3680e+00, -9.4701e+00,  ...,  7.2338e-01,\n           7.9900e-01,  1.7932e+00],\n         [-3.8752e+00,  5.9345e+00, -1.1914e+01,  ...,  8.0444e-01,\n          -3.9522e+00,  1.7272e+00],\n         [-3.3511e+00,  2.0932e+00, -1.0098e+01,  ...,  1.6553e+00,\n          -1.7220e+00,  3.8823e+00],\n         ...,\n         [-2.4636e+00,  4.0947e+00, -6.4984e+00,  ..., -7.9184e-01,\n          -1.7628e+00,  1.4051e+00],\n         [-2.6434e+00,  4.3875e+00, -6.6986e+00,  ..., -6.9326e-01,\n          -1.7476e+00,  1.3277e+00],\n         [-2.4763e+00,  4.5254e+00, -6.4063e+00,  ..., -8.6873e-01,\n          -1.9377e+00,  1.3191e+00]]], grad_fn=<ViewBackward0>)"
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "denoised_out.logits"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-25T03:45:49.638196Z",
     "start_time": "2023-08-25T03:45:49.628670Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "data": {
      "text/plain": "MaskedLMOutput(loss=None, logits=tensor([[[-2.6922,  0.4852, -7.1366,  ..., -0.0273,  0.2026,  1.6019],\n         [-3.4051,  5.4612, -8.9014,  ...,  0.0311, -2.6203,  1.8816],\n         [-3.2442,  4.4054, -8.2776,  ..., -0.4690, -1.5670,  1.8222],\n         ...,\n         [-2.5246,  4.3873, -6.4352,  ..., -0.7323, -1.9798,  1.5046],\n         [-2.8162,  4.2971, -7.1913,  ..., -0.9337, -1.9164,  1.4325],\n         [-2.4159,  4.0938, -6.2263,  ..., -0.9810, -1.8853,  1.6195]]],\n       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)"
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/10099 [00:00<?, ?ex/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f521833bd2884ff99fe620148df02ba8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import DatasetDict\n",
    "from data import prepare_dataset_mlm\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "glosses = create_gloss_vocab(morphology_tree)\n",
    "tokenizer = WordLevelTokenizer(vocab=glosses, model_max_length=64)\n",
    "\n",
    "dataset = DatasetDict()\n",
    "dataset['train'] = prepare_dataset_mlm(data=[line.gloss_list(segmented=True) for line in train_data],\n",
    "                                       tokenizer=tokenizer,\n",
    "                                       device=\"cpu\")\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm_probability=0.15, return_tensors=\"pt\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-25T03:11:06.322775Z",
     "start_time": "2023-08-25T03:11:06.006803Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(572)"
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.count_nonzero(torch.LongTensor(eval['input_ids']) == 0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-25T03:50:05.436864Z",
     "start_time": "2023-08-25T03:50:05.433862Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1334, 64])"
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.LongTensor(eval['input_ids']).size()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-25T03:50:28.459864Z",
     "start_time": "2023-08-25T03:50:28.423742Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'count_zero'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [119], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m preds[torch\u001B[38;5;241m.\u001B[39mLongTensor(\u001B[38;5;28meval\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124minput_ids\u001B[39m\u001B[38;5;124m'\u001B[39m]) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m----> 2\u001B[0m \u001B[43mpreds\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcount_zero\u001B[49m()\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'Tensor' object has no attribute 'count_zero'"
     ]
    }
   ],
   "source": [
    "preds[torch.LongTensor(eval['input_ids']) == 0] = 0\n",
    "preds.count_zero()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-25T03:51:16.996877Z",
     "start_time": "2023-08-25T03:51:16.985096Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(665)"
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(preds == 0).sum()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-25T03:51:43.310020Z",
     "start_time": "2023-08-25T03:51:43.300412Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
