{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/5843 [00:00<?, ?ex/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9d71b1264f0f43d3bf0378f0d4253866"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/612 [00:00<?, ?ex/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0d10bfd71996403f9accf6144fdd6b3e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1334 [00:00<?, ?ex/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "61256484b74548789638ec7a5731e83c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/3644 [00:00<?, ?ex/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "69c84d5fe6024ca9bbecd310102db27e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/481 [00:00<?, ?ex/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "14f87d0debbe4a40aa5ff0a61690a186"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/2219 [00:00<?, ?ex/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b29b2eb94947498bb860d136f4cc30b8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "from data_handling import load_data_file, create_vocab, prepare_dataset, create_gloss_vocab\n",
    "from uspanteko_morphology import morphology\n",
    "from tokenizer import WordLevelTokenizer\n",
    "from datasets import DatasetDict\n",
    "\n",
    "train_data = load_data_file(\"../data/GenBench/categories/story\")\n",
    "eval_advice_data = load_data_file(\"../data/GenBench/categories/advice\")\n",
    "eval_history_data = load_data_file(\"../data/GenBench/categories/history\")\n",
    "eval_personal_data = load_data_file(\"../data/GenBench/categories/personal\")\n",
    "eval_ood = load_data_file(\"../data/GenBench/eval_OOD\")\n",
    "eval_id = load_data_file(\"../data/GenBench/eval_ID\")\n",
    "\n",
    "# print(\n",
    "#     f\"Loaded {len(train_data)} train lines, {len(eval_id_data)} ID eval lines, and {len(eval_ood_data)} OOD eval lines\")\n",
    "\n",
    "MODEL_INPUT_LENGTH = 64\n",
    "device = 'mps'\n",
    "\n",
    "train_vocab = create_vocab([line.morphemes() for line in train_data], threshold=1)\n",
    "tokenizer = WordLevelTokenizer(vocab=train_vocab, model_max_length=MODEL_INPUT_LENGTH)\n",
    "\n",
    "glosses = create_gloss_vocab(morphology)\n",
    "\n",
    "dataset = DatasetDict()\n",
    "\n",
    "dataset['train'] = prepare_dataset(data=train_data, tokenizer=tokenizer, labels=glosses, device=device)\n",
    "dataset['advice'] = prepare_dataset(data=eval_advice_data, tokenizer=tokenizer, labels=glosses, device=device)\n",
    "dataset['history'] = prepare_dataset(data=eval_history_data, tokenizer=tokenizer, labels=glosses, device=device)\n",
    "dataset['personal'] = prepare_dataset(data=eval_personal_data, tokenizer=tokenizer, labels=glosses, device=device)\n",
    "dataset['eval_OOD'] = prepare_dataset(data=eval_ood, tokenizer=tokenizer, labels=glosses, device=device)\n",
    "dataset['eval_ID'] = prepare_dataset(data=eval_id, tokenizer=tokenizer, labels=glosses, device=device)\n",
    "dataset[\"dev\"] = dataset[\"eval_OOD\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-28T00:16:26.972178Z",
     "start_time": "2023-08-28T00:16:01.516472Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file ../models/usp-mlm-absolute-micro/config.json\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"../models/usp-mlm-absolute-micro\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 100,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 64,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 5,\n",
      "  \"num_hidden_layers\": 3,\n",
      "  \"pad_token_id\": 2,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.21.3\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 2284\n",
      "}\n",
      "\n",
      "loading weights file ../models/usp-mlm-absolute-micro/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing RobertaForMaskedLM.\n",
      "\n",
      "All the weights of RobertaForMaskedLM were initialized from the model checkpoint at ../models/usp-mlm-absolute-micro.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForMaskedLM for predictions without further training.\n",
      "PyTorch: setting up devices\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForMaskedLM.forward` and have been ignored: morphemes, glosses, translation, transcription, segmentation. If morphemes, glosses, translation, transcription, segmentation are not expected by `RobertaForMaskedLM.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3644\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='1' max='57' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 1/57 : < :]\n    </div>\n    "
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForMaskedLM.forward` and have been ignored: morphemes, glosses, translation, transcription, segmentation. If morphemes, glosses, translation, transcription, segmentation are not expected by `RobertaForMaskedLM.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1334\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity (personal): 74.42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForMaskedLM.forward` and have been ignored: morphemes, glosses, translation, transcription, segmentation. If morphemes, glosses, translation, transcription, segmentation are not expected by `RobertaForMaskedLM.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 612\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity (history): 80.33\n",
      "Perplexity (advice): 72.03\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments, DataCollatorForLanguageModeling\n",
    "from transformers import AutoModelForMaskedLM\n",
    "\n",
    "model = AutoModelForMaskedLM.from_pretrained(\"../models/usp-mlm-absolute-micro\")\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 2000\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm_probability=0.15, return_tensors=\"pt\")\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=f\"../training-checkpoints\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    gradient_accumulation_steps=3,\n",
    "    weight_decay=0.01,\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=EPOCHS,\n",
    "    report_to=\"wandb\",\n",
    ")\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=dataset['train'],\n",
    "    eval_dataset=dataset['personal'],\n",
    "    data_collator=data_collator\n",
    ")\n",
    "\n",
    "import math\n",
    "\n",
    "eval_results = trainer.evaluate(dataset['personal'])\n",
    "print(f\"Perplexity (personal): {math.exp(eval_results['eval_loss']):.2f}\")\n",
    "\n",
    "eval_results = trainer.evaluate(dataset['history'])\n",
    "print(f\"Perplexity (history): {math.exp(eval_results['eval_loss']):.2f}\")\n",
    "\n",
    "eval_results = trainer.evaluate(dataset['advice'])\n",
    "print(f\"Perplexity (advice): {math.exp(eval_results['eval_loss']):.2f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-28T00:19:38.344542Z",
     "start_time": "2023-08-28T00:19:29.731639Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file ../models/full-flat-1-0.0wd/config.json\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"../models/full-flat-1-0.0wd\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForTokenClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 100,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\",\n",
      "    \"7\": \"LABEL_7\",\n",
      "    \"8\": \"LABEL_8\",\n",
      "    \"9\": \"LABEL_9\",\n",
      "    \"10\": \"LABEL_10\",\n",
      "    \"11\": \"LABEL_11\",\n",
      "    \"12\": \"LABEL_12\",\n",
      "    \"13\": \"LABEL_13\",\n",
      "    \"14\": \"LABEL_14\",\n",
      "    \"15\": \"LABEL_15\",\n",
      "    \"16\": \"LABEL_16\",\n",
      "    \"17\": \"LABEL_17\",\n",
      "    \"18\": \"LABEL_18\",\n",
      "    \"19\": \"LABEL_19\",\n",
      "    \"20\": \"LABEL_20\",\n",
      "    \"21\": \"LABEL_21\",\n",
      "    \"22\": \"LABEL_22\",\n",
      "    \"23\": \"LABEL_23\",\n",
      "    \"24\": \"LABEL_24\",\n",
      "    \"25\": \"LABEL_25\",\n",
      "    \"26\": \"LABEL_26\",\n",
      "    \"27\": \"LABEL_27\",\n",
      "    \"28\": \"LABEL_28\",\n",
      "    \"29\": \"LABEL_29\",\n",
      "    \"30\": \"LABEL_30\",\n",
      "    \"31\": \"LABEL_31\",\n",
      "    \"32\": \"LABEL_32\",\n",
      "    \"33\": \"LABEL_33\",\n",
      "    \"34\": \"LABEL_34\",\n",
      "    \"35\": \"LABEL_35\",\n",
      "    \"36\": \"LABEL_36\",\n",
      "    \"37\": \"LABEL_37\",\n",
      "    \"38\": \"LABEL_38\",\n",
      "    \"39\": \"LABEL_39\",\n",
      "    \"40\": \"LABEL_40\",\n",
      "    \"41\": \"LABEL_41\",\n",
      "    \"42\": \"LABEL_42\",\n",
      "    \"43\": \"LABEL_43\",\n",
      "    \"44\": \"LABEL_44\",\n",
      "    \"45\": \"LABEL_45\",\n",
      "    \"46\": \"LABEL_46\",\n",
      "    \"47\": \"LABEL_47\",\n",
      "    \"48\": \"LABEL_48\",\n",
      "    \"49\": \"LABEL_49\",\n",
      "    \"50\": \"LABEL_50\",\n",
      "    \"51\": \"LABEL_51\",\n",
      "    \"52\": \"LABEL_52\",\n",
      "    \"53\": \"LABEL_53\",\n",
      "    \"54\": \"LABEL_54\",\n",
      "    \"55\": \"LABEL_55\",\n",
      "    \"56\": \"LABEL_56\",\n",
      "    \"57\": \"LABEL_57\",\n",
      "    \"58\": \"LABEL_58\",\n",
      "    \"59\": \"LABEL_59\",\n",
      "    \"60\": \"LABEL_60\",\n",
      "    \"61\": \"LABEL_61\",\n",
      "    \"62\": \"LABEL_62\",\n",
      "    \"63\": \"LABEL_63\",\n",
      "    \"64\": \"LABEL_64\",\n",
      "    \"65\": \"LABEL_65\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_10\": 10,\n",
      "    \"LABEL_11\": 11,\n",
      "    \"LABEL_12\": 12,\n",
      "    \"LABEL_13\": 13,\n",
      "    \"LABEL_14\": 14,\n",
      "    \"LABEL_15\": 15,\n",
      "    \"LABEL_16\": 16,\n",
      "    \"LABEL_17\": 17,\n",
      "    \"LABEL_18\": 18,\n",
      "    \"LABEL_19\": 19,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_20\": 20,\n",
      "    \"LABEL_21\": 21,\n",
      "    \"LABEL_22\": 22,\n",
      "    \"LABEL_23\": 23,\n",
      "    \"LABEL_24\": 24,\n",
      "    \"LABEL_25\": 25,\n",
      "    \"LABEL_26\": 26,\n",
      "    \"LABEL_27\": 27,\n",
      "    \"LABEL_28\": 28,\n",
      "    \"LABEL_29\": 29,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_30\": 30,\n",
      "    \"LABEL_31\": 31,\n",
      "    \"LABEL_32\": 32,\n",
      "    \"LABEL_33\": 33,\n",
      "    \"LABEL_34\": 34,\n",
      "    \"LABEL_35\": 35,\n",
      "    \"LABEL_36\": 36,\n",
      "    \"LABEL_37\": 37,\n",
      "    \"LABEL_38\": 38,\n",
      "    \"LABEL_39\": 39,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_40\": 40,\n",
      "    \"LABEL_41\": 41,\n",
      "    \"LABEL_42\": 42,\n",
      "    \"LABEL_43\": 43,\n",
      "    \"LABEL_44\": 44,\n",
      "    \"LABEL_45\": 45,\n",
      "    \"LABEL_46\": 46,\n",
      "    \"LABEL_47\": 47,\n",
      "    \"LABEL_48\": 48,\n",
      "    \"LABEL_49\": 49,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_50\": 50,\n",
      "    \"LABEL_51\": 51,\n",
      "    \"LABEL_52\": 52,\n",
      "    \"LABEL_53\": 53,\n",
      "    \"LABEL_54\": 54,\n",
      "    \"LABEL_55\": 55,\n",
      "    \"LABEL_56\": 56,\n",
      "    \"LABEL_57\": 57,\n",
      "    \"LABEL_58\": 58,\n",
      "    \"LABEL_59\": 59,\n",
      "    \"LABEL_6\": 6,\n",
      "    \"LABEL_60\": 60,\n",
      "    \"LABEL_61\": 61,\n",
      "    \"LABEL_62\": 62,\n",
      "    \"LABEL_63\": 63,\n",
      "    \"LABEL_64\": 64,\n",
      "    \"LABEL_65\": 65,\n",
      "    \"LABEL_7\": 7,\n",
      "    \"LABEL_8\": 8,\n",
      "    \"LABEL_9\": 9\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 64,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 5,\n",
      "  \"num_hidden_layers\": 3,\n",
      "  \"pad_token_id\": 2,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.21.3\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 2284\n",
      "}\n",
      "\n",
      "loading weights file ../models/full-flat-1-0.0wd/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing RobertaForTokenClassification.\n",
      "\n",
      "All the weights of RobertaForTokenClassification were initialized from the model checkpoint at ../models/full-flat-1-0.0wd.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForTokenClassification for predictions without further training.\n",
      "PyTorch: setting up devices\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForTokenClassification.forward` and have been ignored: morphemes, glosses, translation, transcription, segmentation. If morphemes, glosses, translation, transcription, segmentation are not expected by `RobertaForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2219\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating trainer...\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='1' max='35' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 1/35 : < :]\n    </div>\n    "
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDS [[54  1 65 ... 43 43 43]\n",
      " [ 9 43 43 ... 43 43 43]\n",
      " [ 9 43 43 ... 43 43 43]\n",
      " ...\n",
      " [54 62  1 ... 43 43 43]\n",
      " [ 0  1 43 ... 43 43 43]\n",
      " [60  1 57 ... 43 43 43]]\n",
      "LABELS [[  54    1   26 ... -100 -100 -100]\n",
      " [   9   43 -100 ... -100 -100 -100]\n",
      " [   9   43 -100 ... -100 -100 -100]\n",
      " ...\n",
      " [  54   62    1 ... -100 -100 -100]\n",
      " [  55    1   47 ... -100 -100 -100]\n",
      " [  60    1   54 ... -100 -100 -100]]\n",
      "(2219, 64)\n",
      "Preds:\t ['ADV', '[SEP]', 'PREP', 'VT', 'SC', '[SEP]', 'INC', 'E1S', 'VT', '[SEP]', 'PRON']\n",
      "Labels:\t ['ADV', '[SEP]', 'INC', 'VT', 'SC', '[SEP]', 'INC', 'E1S', 'VI', '[SEP]', 'PRON']\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'eval_loss': 0.9371381402015686,\n 'eval_average_accuracy': 0.6970855803162448,\n 'eval_accuracy': 0.7011510688496461,\n 'eval_runtime': 3.3441,\n 'eval_samples_per_second': 663.55,\n 'eval_steps_per_second': 10.466}"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForTokenClassification\n",
    "from finetune_token_classifier import create_trainer\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"../models/full-flat-1-0.0wd\")\n",
    "\n",
    "trainer = create_trainer(model, dataset=dataset, tokenizer=tokenizer, labels=glosses, batch_size=BATCH_SIZE,\n",
    "                         max_epochs=300, weight_decay=0, report_to='wandb')\n",
    "\n",
    "trainer.evaluate(dataset[\"eval_ID\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-28T00:17:34.122538Z",
     "start_time": "2023-08-28T00:17:30.738036Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForTokenClassification.forward` and have been ignored: morphemes, glosses, translation, transcription, segmentation. If morphemes, glosses, translation, transcription, segmentation are not expected by `RobertaForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 481\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDS [[36  1 50 ... 43 43 43]\n",
      " [38  1 53 ... 43 43 43]\n",
      " [40  1 40 ... 43 43 43]\n",
      " ...\n",
      " [54  1 57 ... 43 43 43]\n",
      " [39  1 53 ... 54 54 54]\n",
      " [26 12 41 ... 39 39 39]]\n",
      "LABELS [[  36    1   50 ... -100 -100 -100]\n",
      " [  45    1   53 ... -100 -100 -100]\n",
      " [  40    1   43 ... -100 -100 -100]\n",
      " ...\n",
      " [  54    1   57 ... -100 -100 -100]\n",
      " [  39    1   53 ... -100 -100 -100]\n",
      " [  26    4   40 ... -100 -100 -100]]\n",
      "(481, 64)\n",
      "Preds:\t ['EXS', '[SEP]', 'NUM', '[SEP]', 'NOM', '[SEP]', 'NOM']\n",
      "Labels:\t ['EXS', '[SEP]', 'NUM', '[SEP]', 'S', '[SEP]', 'DEM']\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'eval_loss': 0.7386803030967712,\n 'eval_average_accuracy': 0.7611720345883254,\n 'eval_accuracy': 0.7661029147175243,\n 'eval_runtime': 0.7167,\n 'eval_samples_per_second': 671.129,\n 'eval_steps_per_second': 11.162}"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(dataset[\"eval_OOD\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-28T00:17:48.965504Z",
     "start_time": "2023-08-28T00:17:48.240258Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "Dataset({\n    features: ['transcription', 'translation', 'glosses', 'segmentation', 'morphemes', 'input_ids', 'attention_mask', 'labels'],\n    num_rows: 481\n})"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"eval_OOD\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-28T00:20:48.843717Z",
     "start_time": "2023-08-28T00:20:48.827817Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file ../models/finetuned-harmonic-micro-absolute/config.json\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"michaelginn/uspanteko-mlm-large\",\n",
      "  \"architectures\": [\n",
      "    \"TaxonomicLossModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 100,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\",\n",
      "    \"7\": \"LABEL_7\",\n",
      "    \"8\": \"LABEL_8\",\n",
      "    \"9\": \"LABEL_9\",\n",
      "    \"10\": \"LABEL_10\",\n",
      "    \"11\": \"LABEL_11\",\n",
      "    \"12\": \"LABEL_12\",\n",
      "    \"13\": \"LABEL_13\",\n",
      "    \"14\": \"LABEL_14\",\n",
      "    \"15\": \"LABEL_15\",\n",
      "    \"16\": \"LABEL_16\",\n",
      "    \"17\": \"LABEL_17\",\n",
      "    \"18\": \"LABEL_18\",\n",
      "    \"19\": \"LABEL_19\",\n",
      "    \"20\": \"LABEL_20\",\n",
      "    \"21\": \"LABEL_21\",\n",
      "    \"22\": \"LABEL_22\",\n",
      "    \"23\": \"LABEL_23\",\n",
      "    \"24\": \"LABEL_24\",\n",
      "    \"25\": \"LABEL_25\",\n",
      "    \"26\": \"LABEL_26\",\n",
      "    \"27\": \"LABEL_27\",\n",
      "    \"28\": \"LABEL_28\",\n",
      "    \"29\": \"LABEL_29\",\n",
      "    \"30\": \"LABEL_30\",\n",
      "    \"31\": \"LABEL_31\",\n",
      "    \"32\": \"LABEL_32\",\n",
      "    \"33\": \"LABEL_33\",\n",
      "    \"34\": \"LABEL_34\",\n",
      "    \"35\": \"LABEL_35\",\n",
      "    \"36\": \"LABEL_36\",\n",
      "    \"37\": \"LABEL_37\",\n",
      "    \"38\": \"LABEL_38\",\n",
      "    \"39\": \"LABEL_39\",\n",
      "    \"40\": \"LABEL_40\",\n",
      "    \"41\": \"LABEL_41\",\n",
      "    \"42\": \"LABEL_42\",\n",
      "    \"43\": \"LABEL_43\",\n",
      "    \"44\": \"LABEL_44\",\n",
      "    \"45\": \"LABEL_45\",\n",
      "    \"46\": \"LABEL_46\",\n",
      "    \"47\": \"LABEL_47\",\n",
      "    \"48\": \"LABEL_48\",\n",
      "    \"49\": \"LABEL_49\",\n",
      "    \"50\": \"LABEL_50\",\n",
      "    \"51\": \"LABEL_51\",\n",
      "    \"52\": \"LABEL_52\",\n",
      "    \"53\": \"LABEL_53\",\n",
      "    \"54\": \"LABEL_54\",\n",
      "    \"55\": \"LABEL_55\",\n",
      "    \"56\": \"LABEL_56\",\n",
      "    \"57\": \"LABEL_57\",\n",
      "    \"58\": \"LABEL_58\",\n",
      "    \"59\": \"LABEL_59\",\n",
      "    \"60\": \"LABEL_60\",\n",
      "    \"61\": \"LABEL_61\",\n",
      "    \"62\": \"LABEL_62\",\n",
      "    \"63\": \"LABEL_63\",\n",
      "    \"64\": \"LABEL_64\",\n",
      "    \"65\": \"LABEL_65\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_10\": 10,\n",
      "    \"LABEL_11\": 11,\n",
      "    \"LABEL_12\": 12,\n",
      "    \"LABEL_13\": 13,\n",
      "    \"LABEL_14\": 14,\n",
      "    \"LABEL_15\": 15,\n",
      "    \"LABEL_16\": 16,\n",
      "    \"LABEL_17\": 17,\n",
      "    \"LABEL_18\": 18,\n",
      "    \"LABEL_19\": 19,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_20\": 20,\n",
      "    \"LABEL_21\": 21,\n",
      "    \"LABEL_22\": 22,\n",
      "    \"LABEL_23\": 23,\n",
      "    \"LABEL_24\": 24,\n",
      "    \"LABEL_25\": 25,\n",
      "    \"LABEL_26\": 26,\n",
      "    \"LABEL_27\": 27,\n",
      "    \"LABEL_28\": 28,\n",
      "    \"LABEL_29\": 29,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_30\": 30,\n",
      "    \"LABEL_31\": 31,\n",
      "    \"LABEL_32\": 32,\n",
      "    \"LABEL_33\": 33,\n",
      "    \"LABEL_34\": 34,\n",
      "    \"LABEL_35\": 35,\n",
      "    \"LABEL_36\": 36,\n",
      "    \"LABEL_37\": 37,\n",
      "    \"LABEL_38\": 38,\n",
      "    \"LABEL_39\": 39,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_40\": 40,\n",
      "    \"LABEL_41\": 41,\n",
      "    \"LABEL_42\": 42,\n",
      "    \"LABEL_43\": 43,\n",
      "    \"LABEL_44\": 44,\n",
      "    \"LABEL_45\": 45,\n",
      "    \"LABEL_46\": 46,\n",
      "    \"LABEL_47\": 47,\n",
      "    \"LABEL_48\": 48,\n",
      "    \"LABEL_49\": 49,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_50\": 50,\n",
      "    \"LABEL_51\": 51,\n",
      "    \"LABEL_52\": 52,\n",
      "    \"LABEL_53\": 53,\n",
      "    \"LABEL_54\": 54,\n",
      "    \"LABEL_55\": 55,\n",
      "    \"LABEL_56\": 56,\n",
      "    \"LABEL_57\": 57,\n",
      "    \"LABEL_58\": 58,\n",
      "    \"LABEL_59\": 59,\n",
      "    \"LABEL_6\": 6,\n",
      "    \"LABEL_60\": 60,\n",
      "    \"LABEL_61\": 61,\n",
      "    \"LABEL_62\": 62,\n",
      "    \"LABEL_63\": 63,\n",
      "    \"LABEL_64\": 64,\n",
      "    \"LABEL_65\": 65,\n",
      "    \"LABEL_7\": 7,\n",
      "    \"LABEL_8\": 8,\n",
      "    \"LABEL_9\": 9\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 64,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 5,\n",
      "  \"num_hidden_layers\": 3,\n",
      "  \"pad_token_id\": 2,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.21.3\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 3477\n",
      "}\n",
      "\n",
      "loading weights file ../models/finetuned-harmonic-micro-absolute/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing TaxonomicLossModel.\n",
      "\n",
      "All the weights of TaxonomicLossModel were initialized from the model checkpoint at ../models/finetuned-harmonic-micro-absolute.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TaxonomicLossModel for predictions without further training.\n",
      "PyTorch: setting up devices\n",
      "The following columns in the evaluation set don't have a corresponding argument in `TaxonomicLossModel.forward` and have been ignored: translation, morphemes, transcription, segmentation, glosses. If translation, morphemes, transcription, segmentation, glosses are not expected by `TaxonomicLossModel.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1334\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating trainer...\n",
      "LEVEL 0 tensor(0.1205)\n",
      "LEVEL 1 tensor(0.1883)\n",
      "LEVEL 2 tensor(0.1997)\n",
      "LEVEL 3 tensor(0.3032)\n",
      "LEVEL 4 tensor(0.6175)\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='1' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 1/21 : < :]\n    </div>\n    "
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LEVEL 0 tensor(0.1926)\n",
      "LEVEL 1 tensor(0.2344)\n",
      "LEVEL 2 tensor(0.2749)\n",
      "LEVEL 3 tensor(0.4350)\n",
      "LEVEL 4 tensor(0.8691)\n",
      "LEVEL 0 tensor(0.1542)\n",
      "LEVEL 1 tensor(0.1739)\n",
      "LEVEL 2 tensor(0.1856)\n",
      "LEVEL 3 tensor(0.2823)\n",
      "LEVEL 4 tensor(0.5788)\n",
      "LEVEL 0 tensor(0.1377)\n",
      "LEVEL 1 tensor(0.1564)\n",
      "LEVEL 2 tensor(0.1737)\n",
      "LEVEL 3 tensor(0.2797)\n",
      "LEVEL 4 tensor(0.5662)\n",
      "LEVEL 0 tensor(0.1106)\n",
      "LEVEL 1 tensor(0.1723)\n",
      "LEVEL 2 tensor(0.2235)\n",
      "LEVEL 3 tensor(0.3381)\n",
      "LEVEL 4 tensor(0.6871)\n",
      "LEVEL 0 tensor(0.1361)\n",
      "LEVEL 1 tensor(0.1433)\n",
      "LEVEL 2 tensor(0.1847)\n",
      "LEVEL 3 tensor(0.2805)\n",
      "LEVEL 4 tensor(0.5678)\n",
      "LEVEL 0 tensor(0.0526)\n",
      "LEVEL 1 tensor(0.1004)\n",
      "LEVEL 2 tensor(0.1376)\n",
      "LEVEL 3 tensor(0.2137)\n",
      "LEVEL 4 tensor(0.4415)\n",
      "LEVEL 0 tensor(0.0972)\n",
      "LEVEL 1 tensor(0.1363)\n",
      "LEVEL 2 tensor(0.1848)\n",
      "LEVEL 3 tensor(0.2861)\n",
      "LEVEL 4 tensor(0.5878)\n",
      "LEVEL 0 tensor(0.1084)\n",
      "LEVEL 1 tensor(0.1465)\n",
      "LEVEL 2 tensor(0.1878)\n",
      "LEVEL 3 tensor(0.3136)\n",
      "LEVEL 4 tensor(0.6470)\n",
      "LEVEL 0 tensor(0.0653)\n",
      "LEVEL 1 tensor(0.0834)\n",
      "LEVEL 2 tensor(0.1266)\n",
      "LEVEL 3 tensor(0.2283)\n",
      "LEVEL 4 tensor(0.4811)\n",
      "LEVEL 0 tensor(0.0975)\n",
      "LEVEL 1 tensor(0.1236)\n",
      "LEVEL 2 tensor(0.1726)\n",
      "LEVEL 3 tensor(0.2916)\n",
      "LEVEL 4 tensor(0.6073)\n",
      "LEVEL 0 tensor(0.1296)\n",
      "LEVEL 1 tensor(0.1378)\n",
      "LEVEL 2 tensor(0.1567)\n",
      "LEVEL 3 tensor(0.2769)\n",
      "LEVEL 4 tensor(0.5696)\n",
      "LEVEL 0 tensor(0.0947)\n",
      "LEVEL 1 tensor(0.1163)\n",
      "LEVEL 2 tensor(0.1486)\n",
      "LEVEL 3 tensor(0.2610)\n",
      "LEVEL 4 tensor(0.5388)\n",
      "LEVEL 0 tensor(0.1375)\n",
      "LEVEL 1 tensor(0.1851)\n",
      "LEVEL 2 tensor(0.2025)\n",
      "LEVEL 3 tensor(0.3268)\n",
      "LEVEL 4 tensor(0.6397)\n",
      "LEVEL 0 tensor(0.0895)\n",
      "LEVEL 1 tensor(0.1229)\n",
      "LEVEL 2 tensor(0.1654)\n",
      "LEVEL 3 tensor(0.2926)\n",
      "LEVEL 4 tensor(0.5919)\n",
      "LEVEL 0 tensor(0.1159)\n",
      "LEVEL 1 tensor(0.1415)\n",
      "LEVEL 2 tensor(0.1865)\n",
      "LEVEL 3 tensor(0.3067)\n",
      "LEVEL 4 tensor(0.6074)\n",
      "LEVEL 0 tensor(0.1134)\n",
      "LEVEL 1 tensor(0.1250)\n",
      "LEVEL 2 tensor(0.1594)\n",
      "LEVEL 3 tensor(0.2723)\n",
      "LEVEL 4 tensor(0.5714)\n",
      "LEVEL 0 tensor(0.1164)\n",
      "LEVEL 1 tensor(0.1499)\n",
      "LEVEL 2 tensor(0.2088)\n",
      "LEVEL 3 tensor(0.3281)\n",
      "LEVEL 4 tensor(0.6902)\n",
      "LEVEL 0 tensor(0.1672)\n",
      "LEVEL 1 tensor(0.1578)\n",
      "LEVEL 2 tensor(0.1582)\n",
      "LEVEL 3 tensor(0.2544)\n",
      "LEVEL 4 tensor(0.5276)\n",
      "LEVEL 0 tensor(0.1494)\n",
      "LEVEL 1 tensor(0.1833)\n",
      "LEVEL 2 tensor(0.2084)\n",
      "LEVEL 3 tensor(0.3546)\n",
      "LEVEL 4 tensor(0.7336)\n",
      "LEVEL 0 tensor(0.0956)\n",
      "LEVEL 1 tensor(0.1086)\n",
      "LEVEL 2 tensor(0.1446)\n",
      "LEVEL 3 tensor(0.2518)\n",
      "LEVEL 4 tensor(0.5244)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDS [[36  1 50 ...  0  0  0]\n",
      " [38  1 53 ...  0  0  0]\n",
      " [40  1 40 ...  0  0  0]\n",
      " ...\n",
      " [42  1 39 ... 54 54 54]\n",
      " [54  1 57 ... 54 54 54]\n",
      " [37 44  1 ...  0  0  0]]\n",
      "LABELS [[36  1 50 ... 66 66 66]\n",
      " [45  1 53 ... 66 66 66]\n",
      " [40  1 43 ... 66 66 66]\n",
      " ...\n",
      " [42  1 39 ... 66 66 66]\n",
      " [54  1 57 ... 66 66 66]\n",
      " [37 44  1 ... 66 66 66]]\n",
      "(1334, 64)\n",
      "Preds:\t ['EXS', '[SEP]', 'NUM', '[SEP]', 'NOM', '[SEP]', 'NOM']\n",
      "Labels:\t ['EXS', '[SEP]', 'NUM', '[SEP]', 'S', '[SEP]', 'DEM']\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'eval_loss': 1.3436601161956787,\n 'eval_average_accuracy': 0.786959505925574,\n 'eval_accuracy': 0.7890538716406921,\n 'eval_runtime': 2.3222,\n 'eval_samples_per_second': 574.446,\n 'eval_steps_per_second': 9.043}"
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from taxonomic_loss_model import TaxonomicLossModel\n",
    "\n",
    "model = TaxonomicLossModel.from_pretrained(\"../models/finetuned-harmonic-micro-absolute\", num_labels=len(glosses),\n",
    "                                           loss_sum='harmonic')\n",
    "model.use_morphology_tree(morphology, max_depth=5)\n",
    "\n",
    "trainer = create_trainer(model, dataset=dataset, tokenizer=tokenizer, labels=glosses, batch_size=BATCH_SIZE,\n",
    "                         max_epochs=300, report_to='wandb')\n",
    "\n",
    "trainer.evaluate(dataset[\"history\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-26T02:05:29.664792Z",
     "start_time": "2023-08-26T02:05:27.291961Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `TaxonomicLossModel.forward` and have been ignored: translation, morphemes, transcription, segmentation, glosses. If translation, morphemes, transcription, segmentation, glosses are not expected by `TaxonomicLossModel.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 4256\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LEVEL 0 tensor(0.1608)\n",
      "LEVEL 1 tensor(0.1406)\n",
      "LEVEL 2 tensor(0.1928)\n",
      "LEVEL 3 tensor(0.3055)\n",
      "LEVEL 4 tensor(0.6462)\n",
      "LEVEL 0 tensor(0.1818)\n",
      "LEVEL 1 tensor(0.1839)\n",
      "LEVEL 2 tensor(0.2246)\n",
      "LEVEL 3 tensor(0.3512)\n",
      "LEVEL 4 tensor(0.7232)\n",
      "LEVEL 0 tensor(0.0829)\n",
      "LEVEL 1 tensor(0.0974)\n",
      "LEVEL 2 tensor(0.1585)\n",
      "LEVEL 3 tensor(0.2417)\n",
      "LEVEL 4 tensor(0.5008)\n",
      "LEVEL 0 tensor(0.1212)\n",
      "LEVEL 1 tensor(0.1372)\n",
      "LEVEL 2 tensor(0.1655)\n",
      "LEVEL 3 tensor(0.2376)\n",
      "LEVEL 4 tensor(0.4712)\n",
      "LEVEL 0 tensor(0.1481)\n",
      "LEVEL 1 tensor(0.1825)\n",
      "LEVEL 2 tensor(0.1983)\n",
      "LEVEL 3 tensor(0.3041)\n",
      "LEVEL 4 tensor(0.6210)\n",
      "LEVEL 0 tensor(0.1221)\n",
      "LEVEL 1 tensor(0.1408)\n",
      "LEVEL 2 tensor(0.1824)\n",
      "LEVEL 3 tensor(0.2885)\n",
      "LEVEL 4 tensor(0.5907)\n",
      "LEVEL 0 tensor(0.1431)\n",
      "LEVEL 1 tensor(0.2021)\n",
      "LEVEL 2 tensor(0.2381)\n",
      "LEVEL 3 tensor(0.3809)\n",
      "LEVEL 4 tensor(0.7718)\n",
      "LEVEL 0 tensor(0.1279)\n",
      "LEVEL 1 tensor(0.1303)\n",
      "LEVEL 2 tensor(0.1568)\n",
      "LEVEL 3 tensor(0.2659)\n",
      "LEVEL 4 tensor(0.5416)\n",
      "LEVEL 0 tensor(0.0886)\n",
      "LEVEL 1 tensor(0.1007)\n",
      "LEVEL 2 tensor(0.1562)\n",
      "LEVEL 3 tensor(0.2590)\n",
      "LEVEL 4 tensor(0.5362)\n",
      "LEVEL 0 tensor(0.1760)\n",
      "LEVEL 1 tensor(0.2143)\n",
      "LEVEL 2 tensor(0.2344)\n",
      "LEVEL 3 tensor(0.3861)\n",
      "LEVEL 4 tensor(0.7976)\n",
      "LEVEL 0 tensor(0.1789)\n",
      "LEVEL 1 tensor(0.2089)\n",
      "LEVEL 2 tensor(0.2553)\n",
      "LEVEL 3 tensor(0.4416)\n",
      "LEVEL 4 tensor(0.8816)\n",
      "LEVEL 0 tensor(0.2166)\n",
      "LEVEL 1 tensor(0.2529)\n",
      "LEVEL 2 tensor(0.3131)\n",
      "LEVEL 3 tensor(0.5245)\n",
      "LEVEL 4 tensor(1.0325)\n",
      "LEVEL 0 tensor(0.1932)\n",
      "LEVEL 1 tensor(0.2392)\n",
      "LEVEL 2 tensor(0.2839)\n",
      "LEVEL 3 tensor(0.4448)\n",
      "LEVEL 4 tensor(0.9179)\n",
      "LEVEL 0 tensor(0.2151)\n",
      "LEVEL 1 tensor(0.2473)\n",
      "LEVEL 2 tensor(0.2793)\n",
      "LEVEL 3 tensor(0.4415)\n",
      "LEVEL 4 tensor(0.8962)\n",
      "LEVEL 0 tensor(0.1608)\n",
      "LEVEL 1 tensor(0.2031)\n",
      "LEVEL 2 tensor(0.2763)\n",
      "LEVEL 3 tensor(0.4375)\n",
      "LEVEL 4 tensor(0.8961)\n",
      "LEVEL 0 tensor(0.1898)\n",
      "LEVEL 1 tensor(0.2145)\n",
      "LEVEL 2 tensor(0.2735)\n",
      "LEVEL 3 tensor(0.4202)\n",
      "LEVEL 4 tensor(0.8670)\n",
      "LEVEL 0 tensor(0.1581)\n",
      "LEVEL 1 tensor(0.2043)\n",
      "LEVEL 2 tensor(0.4581)\n",
      "LEVEL 3 tensor(0.6297)\n",
      "LEVEL 4 tensor(1.2766)\n",
      "LEVEL 0 tensor(0.1772)\n",
      "LEVEL 1 tensor(0.2096)\n",
      "LEVEL 2 tensor(0.4002)\n",
      "LEVEL 3 tensor(0.5756)\n",
      "LEVEL 4 tensor(1.1808)\n",
      "LEVEL 0 tensor(0.2534)\n",
      "LEVEL 1 tensor(0.2643)\n",
      "LEVEL 2 tensor(0.2923)\n",
      "LEVEL 3 tensor(0.4399)\n",
      "LEVEL 4 tensor(0.9223)\n",
      "LEVEL 0 tensor(0.2008)\n",
      "LEVEL 1 tensor(0.2233)\n",
      "LEVEL 2 tensor(0.2679)\n",
      "LEVEL 3 tensor(0.4124)\n",
      "LEVEL 4 tensor(0.8605)\n",
      "LEVEL 0 tensor(0.2356)\n",
      "LEVEL 1 tensor(0.2508)\n",
      "LEVEL 2 tensor(0.2976)\n",
      "LEVEL 3 tensor(0.4650)\n",
      "LEVEL 4 tensor(0.9531)\n",
      "LEVEL 0 tensor(0.2371)\n",
      "LEVEL 1 tensor(0.2271)\n",
      "LEVEL 2 tensor(0.2322)\n",
      "LEVEL 3 tensor(0.3695)\n",
      "LEVEL 4 tensor(0.7793)\n",
      "LEVEL 0 tensor(0.2441)\n",
      "LEVEL 1 tensor(0.2830)\n",
      "LEVEL 2 tensor(0.3101)\n",
      "LEVEL 3 tensor(0.4786)\n",
      "LEVEL 4 tensor(0.9853)\n",
      "LEVEL 0 tensor(0.2479)\n",
      "LEVEL 1 tensor(0.2800)\n",
      "LEVEL 2 tensor(0.3170)\n",
      "LEVEL 3 tensor(0.4702)\n",
      "LEVEL 4 tensor(0.9623)\n",
      "LEVEL 0 tensor(0.1638)\n",
      "LEVEL 1 tensor(0.1846)\n",
      "LEVEL 2 tensor(0.2313)\n",
      "LEVEL 3 tensor(0.3546)\n",
      "LEVEL 4 tensor(0.7864)\n",
      "LEVEL 0 tensor(0.2381)\n",
      "LEVEL 1 tensor(0.3323)\n",
      "LEVEL 2 tensor(0.3690)\n",
      "LEVEL 3 tensor(0.5672)\n",
      "LEVEL 4 tensor(1.1564)\n",
      "LEVEL 0 tensor(0.3229)\n",
      "LEVEL 1 tensor(0.3972)\n",
      "LEVEL 2 tensor(0.3580)\n",
      "LEVEL 3 tensor(0.5450)\n",
      "LEVEL 4 tensor(1.1296)\n",
      "LEVEL 0 tensor(0.1854)\n",
      "LEVEL 1 tensor(0.2344)\n",
      "LEVEL 2 tensor(0.2467)\n",
      "LEVEL 3 tensor(0.3738)\n",
      "LEVEL 4 tensor(0.7701)\n",
      "LEVEL 0 tensor(0.2627)\n",
      "LEVEL 1 tensor(0.3658)\n",
      "LEVEL 2 tensor(0.3512)\n",
      "LEVEL 3 tensor(0.5266)\n",
      "LEVEL 4 tensor(1.0586)\n",
      "LEVEL 0 tensor(0.2083)\n",
      "LEVEL 1 tensor(0.2612)\n",
      "LEVEL 2 tensor(0.3092)\n",
      "LEVEL 3 tensor(0.4560)\n",
      "LEVEL 4 tensor(0.9362)\n",
      "LEVEL 0 tensor(0.2169)\n",
      "LEVEL 1 tensor(0.2933)\n",
      "LEVEL 2 tensor(0.2808)\n",
      "LEVEL 3 tensor(0.4267)\n",
      "LEVEL 4 tensor(0.8836)\n",
      "LEVEL 0 tensor(0.2261)\n",
      "LEVEL 1 tensor(0.2675)\n",
      "LEVEL 2 tensor(0.2792)\n",
      "LEVEL 3 tensor(0.4182)\n",
      "LEVEL 4 tensor(0.8526)\n",
      "LEVEL 0 tensor(0.1991)\n",
      "LEVEL 1 tensor(0.2074)\n",
      "LEVEL 2 tensor(0.2373)\n",
      "LEVEL 3 tensor(0.3591)\n",
      "LEVEL 4 tensor(0.7470)\n",
      "LEVEL 0 tensor(0.2002)\n",
      "LEVEL 1 tensor(0.1986)\n",
      "LEVEL 2 tensor(0.1941)\n",
      "LEVEL 3 tensor(0.2974)\n",
      "LEVEL 4 tensor(0.6244)\n",
      "LEVEL 0 tensor(0.1503)\n",
      "LEVEL 1 tensor(0.1922)\n",
      "LEVEL 2 tensor(0.2055)\n",
      "LEVEL 3 tensor(0.3080)\n",
      "LEVEL 4 tensor(0.6407)\n",
      "LEVEL 0 tensor(0.1869)\n",
      "LEVEL 1 tensor(0.1874)\n",
      "LEVEL 2 tensor(0.1891)\n",
      "LEVEL 3 tensor(0.3126)\n",
      "LEVEL 4 tensor(0.6522)\n",
      "LEVEL 0 tensor(0.1173)\n",
      "LEVEL 1 tensor(0.1366)\n",
      "LEVEL 2 tensor(0.1551)\n",
      "LEVEL 3 tensor(0.2483)\n",
      "LEVEL 4 tensor(0.5095)\n",
      "LEVEL 0 tensor(0.0853)\n",
      "LEVEL 1 tensor(0.1085)\n",
      "LEVEL 2 tensor(0.1361)\n",
      "LEVEL 3 tensor(0.2116)\n",
      "LEVEL 4 tensor(0.4432)\n",
      "LEVEL 0 tensor(0.1348)\n",
      "LEVEL 1 tensor(0.1634)\n",
      "LEVEL 2 tensor(0.1780)\n",
      "LEVEL 3 tensor(0.2717)\n",
      "LEVEL 4 tensor(0.5567)\n",
      "LEVEL 0 tensor(0.1105)\n",
      "LEVEL 1 tensor(0.1374)\n",
      "LEVEL 2 tensor(0.1446)\n",
      "LEVEL 3 tensor(0.2232)\n",
      "LEVEL 4 tensor(0.4615)\n",
      "LEVEL 0 tensor(0.1494)\n",
      "LEVEL 1 tensor(0.1562)\n",
      "LEVEL 2 tensor(0.1557)\n",
      "LEVEL 3 tensor(0.2331)\n",
      "LEVEL 4 tensor(0.4906)\n",
      "LEVEL 0 tensor(0.2390)\n",
      "LEVEL 1 tensor(0.2700)\n",
      "LEVEL 2 tensor(0.2635)\n",
      "LEVEL 3 tensor(0.3942)\n",
      "LEVEL 4 tensor(0.7972)\n",
      "LEVEL 0 tensor(0.2085)\n",
      "LEVEL 1 tensor(0.2547)\n",
      "LEVEL 2 tensor(0.2715)\n",
      "LEVEL 3 tensor(0.4154)\n",
      "LEVEL 4 tensor(0.8365)\n",
      "LEVEL 0 tensor(0.1751)\n",
      "LEVEL 1 tensor(0.1653)\n",
      "LEVEL 2 tensor(0.2122)\n",
      "LEVEL 3 tensor(0.3227)\n",
      "LEVEL 4 tensor(0.6556)\n",
      "LEVEL 0 tensor(0.1496)\n",
      "LEVEL 1 tensor(0.1600)\n",
      "LEVEL 2 tensor(0.2117)\n",
      "LEVEL 3 tensor(0.3334)\n",
      "LEVEL 4 tensor(0.6917)\n",
      "LEVEL 0 tensor(0.1504)\n",
      "LEVEL 1 tensor(0.1496)\n",
      "LEVEL 2 tensor(0.1913)\n",
      "LEVEL 3 tensor(0.2934)\n",
      "LEVEL 4 tensor(0.6041)\n",
      "LEVEL 0 tensor(0.1017)\n",
      "LEVEL 1 tensor(0.1219)\n",
      "LEVEL 2 tensor(0.1647)\n",
      "LEVEL 3 tensor(0.2363)\n",
      "LEVEL 4 tensor(0.4752)\n",
      "LEVEL 0 tensor(0.1387)\n",
      "LEVEL 1 tensor(0.1695)\n",
      "LEVEL 2 tensor(0.1949)\n",
      "LEVEL 3 tensor(0.2982)\n",
      "LEVEL 4 tensor(0.6055)\n",
      "LEVEL 0 tensor(0.1021)\n",
      "LEVEL 1 tensor(0.1214)\n",
      "LEVEL 2 tensor(0.1655)\n",
      "LEVEL 3 tensor(0.2575)\n",
      "LEVEL 4 tensor(0.5269)\n",
      "LEVEL 0 tensor(0.1600)\n",
      "LEVEL 1 tensor(0.2021)\n",
      "LEVEL 2 tensor(0.2275)\n",
      "LEVEL 3 tensor(0.3532)\n",
      "LEVEL 4 tensor(0.7194)\n",
      "LEVEL 0 tensor(0.1409)\n",
      "LEVEL 1 tensor(0.1562)\n",
      "LEVEL 2 tensor(0.1778)\n",
      "LEVEL 3 tensor(0.3107)\n",
      "LEVEL 4 tensor(0.6298)\n",
      "LEVEL 0 tensor(0.0993)\n",
      "LEVEL 1 tensor(0.1129)\n",
      "LEVEL 2 tensor(0.1654)\n",
      "LEVEL 3 tensor(0.2731)\n",
      "LEVEL 4 tensor(0.5650)\n",
      "LEVEL 0 tensor(0.1585)\n",
      "LEVEL 1 tensor(0.1864)\n",
      "LEVEL 2 tensor(0.1922)\n",
      "LEVEL 3 tensor(0.3086)\n",
      "LEVEL 4 tensor(0.6566)\n",
      "LEVEL 0 tensor(0.2428)\n",
      "LEVEL 1 tensor(0.2519)\n",
      "LEVEL 2 tensor(0.2627)\n",
      "LEVEL 3 tensor(0.3962)\n",
      "LEVEL 4 tensor(0.8054)\n",
      "LEVEL 0 tensor(0.2221)\n",
      "LEVEL 1 tensor(0.2288)\n",
      "LEVEL 2 tensor(0.2459)\n",
      "LEVEL 3 tensor(0.3753)\n",
      "LEVEL 4 tensor(0.7708)\n",
      "LEVEL 0 tensor(0.2474)\n",
      "LEVEL 1 tensor(0.2802)\n",
      "LEVEL 2 tensor(0.3067)\n",
      "LEVEL 3 tensor(0.4723)\n",
      "LEVEL 4 tensor(0.9592)\n",
      "LEVEL 0 tensor(0.1897)\n",
      "LEVEL 1 tensor(0.2327)\n",
      "LEVEL 2 tensor(0.2548)\n",
      "LEVEL 3 tensor(0.3866)\n",
      "LEVEL 4 tensor(0.7842)\n",
      "LEVEL 0 tensor(0.2610)\n",
      "LEVEL 1 tensor(0.2089)\n",
      "LEVEL 2 tensor(0.2273)\n",
      "LEVEL 3 tensor(0.3490)\n",
      "LEVEL 4 tensor(0.7399)\n",
      "LEVEL 0 tensor(0.2268)\n",
      "LEVEL 1 tensor(0.2415)\n",
      "LEVEL 2 tensor(0.2683)\n",
      "LEVEL 3 tensor(0.3955)\n",
      "LEVEL 4 tensor(0.8262)\n",
      "LEVEL 0 tensor(0.2017)\n",
      "LEVEL 1 tensor(0.2426)\n",
      "LEVEL 2 tensor(0.2680)\n",
      "LEVEL 3 tensor(0.3925)\n",
      "LEVEL 4 tensor(0.8108)\n",
      "LEVEL 0 tensor(0.2029)\n",
      "LEVEL 1 tensor(0.1899)\n",
      "LEVEL 2 tensor(0.2204)\n",
      "LEVEL 3 tensor(0.3325)\n",
      "LEVEL 4 tensor(0.6853)\n",
      "LEVEL 0 tensor(0.2731)\n",
      "LEVEL 1 tensor(0.2670)\n",
      "LEVEL 2 tensor(0.2747)\n",
      "LEVEL 3 tensor(0.4189)\n",
      "LEVEL 4 tensor(0.8658)\n",
      "LEVEL 0 tensor(0.1588)\n",
      "LEVEL 1 tensor(0.1812)\n",
      "LEVEL 2 tensor(0.2139)\n",
      "LEVEL 3 tensor(0.3226)\n",
      "LEVEL 4 tensor(0.7003)\n",
      "LEVEL 0 tensor(0.2515)\n",
      "LEVEL 1 tensor(0.2689)\n",
      "LEVEL 2 tensor(0.2886)\n",
      "LEVEL 3 tensor(0.4473)\n",
      "LEVEL 4 tensor(0.9246)\n",
      "LEVEL 0 tensor(0.2190)\n",
      "LEVEL 1 tensor(0.2527)\n",
      "LEVEL 2 tensor(0.2939)\n",
      "LEVEL 3 tensor(0.4321)\n",
      "LEVEL 4 tensor(0.9189)\n",
      "LEVEL 0 tensor(0.1583)\n",
      "LEVEL 1 tensor(0.1976)\n",
      "LEVEL 2 tensor(0.2231)\n",
      "LEVEL 3 tensor(0.3386)\n",
      "LEVEL 4 tensor(0.6902)\n",
      "LEVEL 0 tensor(0.1076)\n",
      "LEVEL 1 tensor(0.1598)\n",
      "LEVEL 2 tensor(0.1719)\n",
      "LEVEL 3 tensor(0.2831)\n",
      "LEVEL 4 tensor(0.6295)\n",
      "PREDS [[54  1 65 ... 54 54 54]\n",
      " [ 9 43  0 ...  0  0  0]\n",
      " [ 9 43  0 ...  0  0  0]\n",
      " ...\n",
      " [57  1 50 ...  0  0  0]\n",
      " [39  1 53 ...  0  0  0]\n",
      " [ 5 53  1 ...  0  0  0]]\n",
      "LABELS [[54  1 26 ... 66 66 66]\n",
      " [ 9 43 66 ... 66 66 66]\n",
      " [ 9 43 66 ... 66 66 66]\n",
      " ...\n",
      " [57  1 50 ... 66 66 66]\n",
      " [43  1 53 ... 66 66 66]\n",
      " [ 3 53  1 ... 66 66 66]]\n",
      "(4256, 64)\n",
      "Preds:\t ['ADV', '[SEP]', 'PREP', 'VT', 'SC', '[SEP]', 'INC', 'E1S', 'VT', '[SEP]', 'PRON']\n",
      "Labels:\t ['ADV', '[SEP]', 'INC', 'VT', 'SC', '[SEP]', 'INC', 'E1S', 'VI', '[SEP]', 'PRON']\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'eval_loss': 1.769002079963684,\n 'eval_average_accuracy': 0.7375037916324279,\n 'eval_accuracy': 0.7433526011560694,\n 'eval_runtime': 7.074,\n 'eval_samples_per_second': 601.643,\n 'eval_steps_per_second': 9.471}"
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(dataset[\"eval_OOD\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-26T02:06:15.385726Z",
     "start_time": "2023-08-26T02:06:08.305374Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file ../models/usp-lang-relative_key_query-micro/config.json\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"../models/usp-lang-relative_key_query-micro\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 100,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\",\n",
      "    \"7\": \"LABEL_7\",\n",
      "    \"8\": \"LABEL_8\",\n",
      "    \"9\": \"LABEL_9\",\n",
      "    \"10\": \"LABEL_10\",\n",
      "    \"11\": \"LABEL_11\",\n",
      "    \"12\": \"LABEL_12\",\n",
      "    \"13\": \"LABEL_13\",\n",
      "    \"14\": \"LABEL_14\",\n",
      "    \"15\": \"LABEL_15\",\n",
      "    \"16\": \"LABEL_16\",\n",
      "    \"17\": \"LABEL_17\",\n",
      "    \"18\": \"LABEL_18\",\n",
      "    \"19\": \"LABEL_19\",\n",
      "    \"20\": \"LABEL_20\",\n",
      "    \"21\": \"LABEL_21\",\n",
      "    \"22\": \"LABEL_22\",\n",
      "    \"23\": \"LABEL_23\",\n",
      "    \"24\": \"LABEL_24\",\n",
      "    \"25\": \"LABEL_25\",\n",
      "    \"26\": \"LABEL_26\",\n",
      "    \"27\": \"LABEL_27\",\n",
      "    \"28\": \"LABEL_28\",\n",
      "    \"29\": \"LABEL_29\",\n",
      "    \"30\": \"LABEL_30\",\n",
      "    \"31\": \"LABEL_31\",\n",
      "    \"32\": \"LABEL_32\",\n",
      "    \"33\": \"LABEL_33\",\n",
      "    \"34\": \"LABEL_34\",\n",
      "    \"35\": \"LABEL_35\",\n",
      "    \"36\": \"LABEL_36\",\n",
      "    \"37\": \"LABEL_37\",\n",
      "    \"38\": \"LABEL_38\",\n",
      "    \"39\": \"LABEL_39\",\n",
      "    \"40\": \"LABEL_40\",\n",
      "    \"41\": \"LABEL_41\",\n",
      "    \"42\": \"LABEL_42\",\n",
      "    \"43\": \"LABEL_43\",\n",
      "    \"44\": \"LABEL_44\",\n",
      "    \"45\": \"LABEL_45\",\n",
      "    \"46\": \"LABEL_46\",\n",
      "    \"47\": \"LABEL_47\",\n",
      "    \"48\": \"LABEL_48\",\n",
      "    \"49\": \"LABEL_49\",\n",
      "    \"50\": \"LABEL_50\",\n",
      "    \"51\": \"LABEL_51\",\n",
      "    \"52\": \"LABEL_52\",\n",
      "    \"53\": \"LABEL_53\",\n",
      "    \"54\": \"LABEL_54\",\n",
      "    \"55\": \"LABEL_55\",\n",
      "    \"56\": \"LABEL_56\",\n",
      "    \"57\": \"LABEL_57\",\n",
      "    \"58\": \"LABEL_58\",\n",
      "    \"59\": \"LABEL_59\",\n",
      "    \"60\": \"LABEL_60\",\n",
      "    \"61\": \"LABEL_61\",\n",
      "    \"62\": \"LABEL_62\",\n",
      "    \"63\": \"LABEL_63\",\n",
      "    \"64\": \"LABEL_64\",\n",
      "    \"65\": \"LABEL_65\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_10\": 10,\n",
      "    \"LABEL_11\": 11,\n",
      "    \"LABEL_12\": 12,\n",
      "    \"LABEL_13\": 13,\n",
      "    \"LABEL_14\": 14,\n",
      "    \"LABEL_15\": 15,\n",
      "    \"LABEL_16\": 16,\n",
      "    \"LABEL_17\": 17,\n",
      "    \"LABEL_18\": 18,\n",
      "    \"LABEL_19\": 19,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_20\": 20,\n",
      "    \"LABEL_21\": 21,\n",
      "    \"LABEL_22\": 22,\n",
      "    \"LABEL_23\": 23,\n",
      "    \"LABEL_24\": 24,\n",
      "    \"LABEL_25\": 25,\n",
      "    \"LABEL_26\": 26,\n",
      "    \"LABEL_27\": 27,\n",
      "    \"LABEL_28\": 28,\n",
      "    \"LABEL_29\": 29,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_30\": 30,\n",
      "    \"LABEL_31\": 31,\n",
      "    \"LABEL_32\": 32,\n",
      "    \"LABEL_33\": 33,\n",
      "    \"LABEL_34\": 34,\n",
      "    \"LABEL_35\": 35,\n",
      "    \"LABEL_36\": 36,\n",
      "    \"LABEL_37\": 37,\n",
      "    \"LABEL_38\": 38,\n",
      "    \"LABEL_39\": 39,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_40\": 40,\n",
      "    \"LABEL_41\": 41,\n",
      "    \"LABEL_42\": 42,\n",
      "    \"LABEL_43\": 43,\n",
      "    \"LABEL_44\": 44,\n",
      "    \"LABEL_45\": 45,\n",
      "    \"LABEL_46\": 46,\n",
      "    \"LABEL_47\": 47,\n",
      "    \"LABEL_48\": 48,\n",
      "    \"LABEL_49\": 49,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_50\": 50,\n",
      "    \"LABEL_51\": 51,\n",
      "    \"LABEL_52\": 52,\n",
      "    \"LABEL_53\": 53,\n",
      "    \"LABEL_54\": 54,\n",
      "    \"LABEL_55\": 55,\n",
      "    \"LABEL_56\": 56,\n",
      "    \"LABEL_57\": 57,\n",
      "    \"LABEL_58\": 58,\n",
      "    \"LABEL_59\": 59,\n",
      "    \"LABEL_6\": 6,\n",
      "    \"LABEL_60\": 60,\n",
      "    \"LABEL_61\": 61,\n",
      "    \"LABEL_62\": 62,\n",
      "    \"LABEL_63\": 63,\n",
      "    \"LABEL_64\": 64,\n",
      "    \"LABEL_65\": 65,\n",
      "    \"LABEL_7\": 7,\n",
      "    \"LABEL_8\": 8,\n",
      "    \"LABEL_9\": 9\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 64,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 5,\n",
      "  \"num_hidden_layers\": 3,\n",
      "  \"pad_token_id\": 2,\n",
      "  \"position_embedding_type\": \"relative_key_query\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.21.3\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 2284\n",
      "}\n",
      "\n",
      "loading weights file ../models/usp-lang-relative_key_query-micro/pytorch_model.bin\n",
      "Some weights of the model checkpoint at ../models/usp-lang-relative_key_query-micro were not used when initializing RobertaForTokenClassification: ['lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at ../models/usp-lang-relative_key_query-micro and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "The following columns in the training set don't have a corresponding argument in `RobertaForTokenClassification.forward` and have been ignored: translation, morphemes, transcription, segmentation, glosses. If translation, morphemes, transcription, segmentation, glosses are not expected by `RobertaForTokenClassification.forward`,  you can safely ignore this message.\n",
      "/Users/milesper/miniforge3/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 5843\n",
      "  Num Epochs = 300\n",
      "  Instantaneous batch size per device = 64\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 192\n",
      "  Gradient Accumulation steps = 3\n",
      "  Total optimization steps = 9000\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating trainer...\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='2' max='9000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [   2/9000 : < :, Epoch 0.03/300]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForTokenClassification.forward` and have been ignored: translation, morphemes, transcription, segmentation, glosses. If translation, morphemes, transcription, segmentation, glosses are not expected by `RobertaForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1334\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDS [[54  1 54 ... 43 43 43]\n",
      " [ 1  1 54 ... 43 43 43]\n",
      " [43  1 54 ... 43 43 43]\n",
      " ...\n",
      " [54  1 43 ... 43 43 43]\n",
      " [54  1 39 ... 43 43 43]\n",
      " [43 43  1 ... 43 43 43]]\n",
      "LABELS [[  36    1   50 ... -100 -100 -100]\n",
      " [  45    1   53 ... -100 -100 -100]\n",
      " [  40    1   43 ... -100 -100 -100]\n",
      " ...\n",
      " [  42    1   39 ... -100 -100 -100]\n",
      " [  54    1   57 ... -100 -100 -100]\n",
      " [  37   44    1 ... -100 -100 -100]]\n",
      "(1334, 64)\n",
      "Preds:\t ['ADV', '[SEP]', 'ADV', '[SEP]', 'ADV', '[SEP]', 'ADV']\n",
      "Labels:\t ['EXS', '[SEP]', 'NUM', '[SEP]', 'S', '[SEP]', 'DEM']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ../training-checkpoints/checkpoint-30\n",
      "Configuration saved in ../training-checkpoints/checkpoint-30/config.json\n",
      "Model weights saved in ../training-checkpoints/checkpoint-30/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForTokenClassification.forward` and have been ignored: translation, morphemes, transcription, segmentation, glosses. If translation, morphemes, transcription, segmentation, glosses are not expected by `RobertaForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1334\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDS [[54  1 54 ... 43 43 43]\n",
      " [38  1 54 ... 43 43 43]\n",
      " [43  1 54 ... 43 43 43]\n",
      " ...\n",
      " [54  1 43 ... 43 43 43]\n",
      " [54  1 54 ... 43 43 43]\n",
      " [43 43  1 ... 43 43 43]]\n",
      "LABELS [[  36    1   50 ... -100 -100 -100]\n",
      " [  45    1   53 ... -100 -100 -100]\n",
      " [  40    1   43 ... -100 -100 -100]\n",
      " ...\n",
      " [  42    1   39 ... -100 -100 -100]\n",
      " [  54    1   57 ... -100 -100 -100]\n",
      " [  37   44    1 ... -100 -100 -100]]\n",
      "(1334, 64)\n",
      "Preds:\t ['ADV', '[SEP]', 'ADV', '[SEP]', 'ADV', '[SEP]', 'ADV']\n",
      "Labels:\t ['EXS', '[SEP]', 'NUM', '[SEP]', 'S', '[SEP]', 'DEM']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ../training-checkpoints/checkpoint-60\n",
      "Configuration saved in ../training-checkpoints/checkpoint-60/config.json\n",
      "Model weights saved in ../training-checkpoints/checkpoint-60/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForTokenClassification.forward` and have been ignored: translation, morphemes, transcription, segmentation, glosses. If translation, morphemes, transcription, segmentation, glosses are not expected by `RobertaForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1334\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDS [[54  1 54 ... 43 43 43]\n",
      " [38  1 53 ... 43 43 43]\n",
      " [43  1 54 ... 43 43 43]\n",
      " ...\n",
      " [42  1 43 ... 43 43 43]\n",
      " [54  1 54 ... 43 43 43]\n",
      " [43 43  1 ... 43 43 43]]\n",
      "LABELS [[  36    1   50 ... -100 -100 -100]\n",
      " [  45    1   53 ... -100 -100 -100]\n",
      " [  40    1   43 ... -100 -100 -100]\n",
      " ...\n",
      " [  42    1   39 ... -100 -100 -100]\n",
      " [  54    1   57 ... -100 -100 -100]\n",
      " [  37   44    1 ... -100 -100 -100]]\n",
      "(1334, 64)\n",
      "Preds:\t ['ADV', '[SEP]', 'ADV', '[SEP]', 'ADV', '[SEP]', 'ADV']\n",
      "Labels:\t ['EXS', '[SEP]', 'NUM', '[SEP]', 'S', '[SEP]', 'DEM']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ../training-checkpoints/checkpoint-90\n",
      "Configuration saved in ../training-checkpoints/checkpoint-90/config.json\n",
      "Model weights saved in ../training-checkpoints/checkpoint-90/pytorch_model.bin\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [253], line 7\u001B[0m\n\u001B[1;32m      2\u001B[0m model \u001B[38;5;241m=\u001B[39m AutoModelForTokenClassification\u001B[38;5;241m.\u001B[39mfrom_pretrained(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m../models/usp-lang-relative_key_query-micro\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m      3\u001B[0m                                                         num_labels\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mlen\u001B[39m(glosses))\n\u001B[1;32m      4\u001B[0m trainer \u001B[38;5;241m=\u001B[39m create_trainer(model, dataset\u001B[38;5;241m=\u001B[39mdataset, tokenizer\u001B[38;5;241m=\u001B[39mtokenizer, labels\u001B[38;5;241m=\u001B[39mglosses, batch_size\u001B[38;5;241m=\u001B[39mBATCH_SIZE,\n\u001B[1;32m      5\u001B[0m                          max_epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m300\u001B[39m, report_to\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mwandb\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m----> 7\u001B[0m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniforge3/lib/python3.10/site-packages/transformers/trainer.py:1498\u001B[0m, in \u001B[0;36mTrainer.train\u001B[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001B[0m\n\u001B[1;32m   1493\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel_wrapped \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel\n\u001B[1;32m   1495\u001B[0m inner_training_loop \u001B[38;5;241m=\u001B[39m find_executable_batch_size(\n\u001B[1;32m   1496\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_inner_training_loop, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_train_batch_size, args\u001B[38;5;241m.\u001B[39mauto_find_batch_size\n\u001B[1;32m   1497\u001B[0m )\n\u001B[0;32m-> 1498\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43minner_training_loop\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1499\u001B[0m \u001B[43m    \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1500\u001B[0m \u001B[43m    \u001B[49m\u001B[43mresume_from_checkpoint\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mresume_from_checkpoint\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1501\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrial\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrial\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1502\u001B[0m \u001B[43m    \u001B[49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1503\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniforge3/lib/python3.10/site-packages/transformers/trainer.py:1740\u001B[0m, in \u001B[0;36mTrainer._inner_training_loop\u001B[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001B[0m\n\u001B[1;32m   1738\u001B[0m         tr_loss_step \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining_step(model, inputs)\n\u001B[1;32m   1739\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1740\u001B[0m     tr_loss_step \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtraining_step\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1742\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[1;32m   1743\u001B[0m     args\u001B[38;5;241m.\u001B[39mlogging_nan_inf_filter\n\u001B[1;32m   1744\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_torch_tpu_available()\n\u001B[1;32m   1745\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m (torch\u001B[38;5;241m.\u001B[39misnan(tr_loss_step) \u001B[38;5;129;01mor\u001B[39;00m torch\u001B[38;5;241m.\u001B[39misinf(tr_loss_step))\n\u001B[1;32m   1746\u001B[0m ):\n\u001B[1;32m   1747\u001B[0m     \u001B[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001B[39;00m\n\u001B[1;32m   1748\u001B[0m     tr_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m tr_loss \u001B[38;5;241m/\u001B[39m (\u001B[38;5;241m1\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mglobal_step \u001B[38;5;241m-\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_globalstep_last_logged)\n",
      "File \u001B[0;32m~/miniforge3/lib/python3.10/site-packages/transformers/trainer.py:2470\u001B[0m, in \u001B[0;36mTrainer.training_step\u001B[0;34m(self, model, inputs)\u001B[0m\n\u001B[1;32m   2467\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m loss_mb\u001B[38;5;241m.\u001B[39mreduce_mean()\u001B[38;5;241m.\u001B[39mdetach()\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[1;32m   2469\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcompute_loss_context_manager():\n\u001B[0;32m-> 2470\u001B[0m     loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompute_loss\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2472\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mn_gpu \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m   2473\u001B[0m     loss \u001B[38;5;241m=\u001B[39m loss\u001B[38;5;241m.\u001B[39mmean()  \u001B[38;5;66;03m# mean() to average on multi-gpu parallel training\u001B[39;00m\n",
      "File \u001B[0;32m~/miniforge3/lib/python3.10/site-packages/transformers/trainer.py:2502\u001B[0m, in \u001B[0;36mTrainer.compute_loss\u001B[0;34m(self, model, inputs, return_outputs)\u001B[0m\n\u001B[1;32m   2500\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   2501\u001B[0m     labels \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m-> 2502\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2503\u001B[0m \u001B[38;5;66;03m# Save past state if it exists\u001B[39;00m\n\u001B[1;32m   2504\u001B[0m \u001B[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001B[39;00m\n\u001B[1;32m   2505\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mpast_index \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
      "File \u001B[0;32m~/miniforge3/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1186\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1187\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1188\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1189\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1190\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1191\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1192\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/miniforge3/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py:1401\u001B[0m, in \u001B[0;36mRobertaForTokenClassification.forward\u001B[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[1;32m   1395\u001B[0m \u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   1396\u001B[0m \u001B[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\u001B[39;00m\n\u001B[1;32m   1397\u001B[0m \u001B[38;5;124;03m    Labels for computing the token classification loss. Indices should be in `[0, ..., config.num_labels - 1]`.\u001B[39;00m\n\u001B[1;32m   1398\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   1399\u001B[0m return_dict \u001B[38;5;241m=\u001B[39m return_dict \u001B[38;5;28;01mif\u001B[39;00m return_dict \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39muse_return_dict\n\u001B[0;32m-> 1401\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mroberta\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1402\u001B[0m \u001B[43m    \u001B[49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1403\u001B[0m \u001B[43m    \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1404\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtoken_type_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtoken_type_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1405\u001B[0m \u001B[43m    \u001B[49m\u001B[43mposition_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mposition_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1406\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhead_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1407\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs_embeds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs_embeds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1408\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1409\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1410\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1411\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1413\u001B[0m sequence_output \u001B[38;5;241m=\u001B[39m outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m   1415\u001B[0m sequence_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdropout(sequence_output)\n",
      "File \u001B[0;32m~/miniforge3/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1186\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1187\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1188\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1189\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1190\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1191\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1192\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/miniforge3/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py:848\u001B[0m, in \u001B[0;36mRobertaModel.forward\u001B[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[1;32m    839\u001B[0m head_mask \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_head_mask(head_mask, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mnum_hidden_layers)\n\u001B[1;32m    841\u001B[0m embedding_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39membeddings(\n\u001B[1;32m    842\u001B[0m     input_ids\u001B[38;5;241m=\u001B[39minput_ids,\n\u001B[1;32m    843\u001B[0m     position_ids\u001B[38;5;241m=\u001B[39mposition_ids,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    846\u001B[0m     past_key_values_length\u001B[38;5;241m=\u001B[39mpast_key_values_length,\n\u001B[1;32m    847\u001B[0m )\n\u001B[0;32m--> 848\u001B[0m encoder_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoder\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    849\u001B[0m \u001B[43m    \u001B[49m\u001B[43membedding_output\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    850\u001B[0m \u001B[43m    \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextended_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    851\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhead_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    852\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    853\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoder_attention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoder_extended_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    854\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpast_key_values\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpast_key_values\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    855\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_cache\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_cache\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    856\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    857\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    858\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    859\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    860\u001B[0m sequence_output \u001B[38;5;241m=\u001B[39m encoder_outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m    861\u001B[0m pooled_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpooler(sequence_output) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpooler \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/miniforge3/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1186\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1187\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1188\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1189\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1190\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1191\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1192\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/miniforge3/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py:524\u001B[0m, in \u001B[0;36mRobertaEncoder.forward\u001B[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[1;32m    515\u001B[0m     layer_outputs \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mutils\u001B[38;5;241m.\u001B[39mcheckpoint\u001B[38;5;241m.\u001B[39mcheckpoint(\n\u001B[1;32m    516\u001B[0m         create_custom_forward(layer_module),\n\u001B[1;32m    517\u001B[0m         hidden_states,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    521\u001B[0m         encoder_attention_mask,\n\u001B[1;32m    522\u001B[0m     )\n\u001B[1;32m    523\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 524\u001B[0m     layer_outputs \u001B[38;5;241m=\u001B[39m \u001B[43mlayer_module\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    525\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    526\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    527\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlayer_head_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    528\u001B[0m \u001B[43m        \u001B[49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    529\u001B[0m \u001B[43m        \u001B[49m\u001B[43mencoder_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    530\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpast_key_value\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    531\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    532\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    534\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m layer_outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m    535\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m use_cache:\n",
      "File \u001B[0;32m~/miniforge3/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1186\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1187\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1188\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1189\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1190\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1191\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1192\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/miniforge3/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py:451\u001B[0m, in \u001B[0;36mRobertaLayer.forward\u001B[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001B[0m\n\u001B[1;32m    448\u001B[0m     cross_attn_present_key_value \u001B[38;5;241m=\u001B[39m cross_attention_outputs[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\n\u001B[1;32m    449\u001B[0m     present_key_value \u001B[38;5;241m=\u001B[39m present_key_value \u001B[38;5;241m+\u001B[39m cross_attn_present_key_value\n\u001B[0;32m--> 451\u001B[0m layer_output \u001B[38;5;241m=\u001B[39m \u001B[43mapply_chunking_to_forward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    452\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfeed_forward_chunk\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mchunk_size_feed_forward\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mseq_len_dim\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattention_output\u001B[49m\n\u001B[1;32m    453\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    454\u001B[0m outputs \u001B[38;5;241m=\u001B[39m (layer_output,) \u001B[38;5;241m+\u001B[39m outputs\n\u001B[1;32m    456\u001B[0m \u001B[38;5;66;03m# if decoder, return the attn key/values as the last output\u001B[39;00m\n",
      "File \u001B[0;32m~/miniforge3/lib/python3.10/site-packages/transformers/pytorch_utils.py:243\u001B[0m, in \u001B[0;36mapply_chunking_to_forward\u001B[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001B[0m\n\u001B[1;32m    240\u001B[0m     \u001B[38;5;66;03m# concatenate output at same dimension\u001B[39;00m\n\u001B[1;32m    241\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mcat(output_chunks, dim\u001B[38;5;241m=\u001B[39mchunk_dim)\n\u001B[0;32m--> 243\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43minput_tensors\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniforge3/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py:464\u001B[0m, in \u001B[0;36mRobertaLayer.feed_forward_chunk\u001B[0;34m(self, attention_output)\u001B[0m\n\u001B[1;32m    462\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfeed_forward_chunk\u001B[39m(\u001B[38;5;28mself\u001B[39m, attention_output):\n\u001B[1;32m    463\u001B[0m     intermediate_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mintermediate(attention_output)\n\u001B[0;32m--> 464\u001B[0m     layer_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moutput\u001B[49m\u001B[43m(\u001B[49m\u001B[43mintermediate_output\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattention_output\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    465\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m layer_output\n",
      "File \u001B[0;32m~/miniforge3/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1186\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1187\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1188\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1189\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1190\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1191\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1192\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/miniforge3/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py:376\u001B[0m, in \u001B[0;36mRobertaOutput.forward\u001B[0;34m(self, hidden_states, input_tensor)\u001B[0m\n\u001B[1;32m    374\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, hidden_states: torch\u001B[38;5;241m.\u001B[39mTensor, input_tensor: torch\u001B[38;5;241m.\u001B[39mTensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m torch\u001B[38;5;241m.\u001B[39mTensor:\n\u001B[1;32m    375\u001B[0m     hidden_states \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdense(hidden_states)\n\u001B[0;32m--> 376\u001B[0m     hidden_states \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdropout\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    377\u001B[0m     hidden_states \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mLayerNorm(hidden_states \u001B[38;5;241m+\u001B[39m input_tensor)\n\u001B[1;32m    378\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m hidden_states\n",
      "File \u001B[0;32m~/miniforge3/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1186\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1187\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1188\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1189\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1190\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1191\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1192\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/miniforge3/lib/python3.10/site-packages/torch/nn/modules/dropout.py:59\u001B[0m, in \u001B[0;36mDropout.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m     58\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m---> 59\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdropout\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mp\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtraining\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minplace\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniforge3/lib/python3.10/site-packages/torch/nn/functional.py:1252\u001B[0m, in \u001B[0;36mdropout\u001B[0;34m(input, p, training, inplace)\u001B[0m\n\u001B[1;32m   1250\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m p \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m0.0\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m p \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1.0\u001B[39m:\n\u001B[1;32m   1251\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdropout probability has to be between 0 and 1, \u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbut got \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(p))\n\u001B[0;32m-> 1252\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m _VF\u001B[38;5;241m.\u001B[39mdropout_(\u001B[38;5;28minput\u001B[39m, p, training) \u001B[38;5;28;01mif\u001B[39;00m inplace \u001B[38;5;28;01melse\u001B[39;00m \u001B[43m_VF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdropout\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mp\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtraining\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "dataset[\"dev\"] = dataset[\"history\"]\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"../models/usp-lang-relative_key_query-micro\",\n",
    "                                                        num_labels=len(glosses))\n",
    "trainer = create_trainer(model, dataset=dataset, tokenizer=tokenizer, labels=glosses, batch_size=BATCH_SIZE,\n",
    "                         max_epochs=300, report_to='wandb')\n",
    "\n",
    "trainer.train()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-26T16:40:15.069692Z",
     "start_time": "2023-08-26T16:38:46.916691Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/michaelginn/usp-mlm-genbench/resolve/main/config.json from cache at /Users/milesper/.cache/huggingface/transformers/a9afbb4060625af7d7df340d4b3c12529a2ce02389d93941e0a9c0e816028821.6397773dd83107d1040497818bcfcc0e22d450f16335ecd6c34d128812d92083\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"michaelginn/usp-mlm-genbench\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 100,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\",\n",
      "    \"7\": \"LABEL_7\",\n",
      "    \"8\": \"LABEL_8\",\n",
      "    \"9\": \"LABEL_9\",\n",
      "    \"10\": \"LABEL_10\",\n",
      "    \"11\": \"LABEL_11\",\n",
      "    \"12\": \"LABEL_12\",\n",
      "    \"13\": \"LABEL_13\",\n",
      "    \"14\": \"LABEL_14\",\n",
      "    \"15\": \"LABEL_15\",\n",
      "    \"16\": \"LABEL_16\",\n",
      "    \"17\": \"LABEL_17\",\n",
      "    \"18\": \"LABEL_18\",\n",
      "    \"19\": \"LABEL_19\",\n",
      "    \"20\": \"LABEL_20\",\n",
      "    \"21\": \"LABEL_21\",\n",
      "    \"22\": \"LABEL_22\",\n",
      "    \"23\": \"LABEL_23\",\n",
      "    \"24\": \"LABEL_24\",\n",
      "    \"25\": \"LABEL_25\",\n",
      "    \"26\": \"LABEL_26\",\n",
      "    \"27\": \"LABEL_27\",\n",
      "    \"28\": \"LABEL_28\",\n",
      "    \"29\": \"LABEL_29\",\n",
      "    \"30\": \"LABEL_30\",\n",
      "    \"31\": \"LABEL_31\",\n",
      "    \"32\": \"LABEL_32\",\n",
      "    \"33\": \"LABEL_33\",\n",
      "    \"34\": \"LABEL_34\",\n",
      "    \"35\": \"LABEL_35\",\n",
      "    \"36\": \"LABEL_36\",\n",
      "    \"37\": \"LABEL_37\",\n",
      "    \"38\": \"LABEL_38\",\n",
      "    \"39\": \"LABEL_39\",\n",
      "    \"40\": \"LABEL_40\",\n",
      "    \"41\": \"LABEL_41\",\n",
      "    \"42\": \"LABEL_42\",\n",
      "    \"43\": \"LABEL_43\",\n",
      "    \"44\": \"LABEL_44\",\n",
      "    \"45\": \"LABEL_45\",\n",
      "    \"46\": \"LABEL_46\",\n",
      "    \"47\": \"LABEL_47\",\n",
      "    \"48\": \"LABEL_48\",\n",
      "    \"49\": \"LABEL_49\",\n",
      "    \"50\": \"LABEL_50\",\n",
      "    \"51\": \"LABEL_51\",\n",
      "    \"52\": \"LABEL_52\",\n",
      "    \"53\": \"LABEL_53\",\n",
      "    \"54\": \"LABEL_54\",\n",
      "    \"55\": \"LABEL_55\",\n",
      "    \"56\": \"LABEL_56\",\n",
      "    \"57\": \"LABEL_57\",\n",
      "    \"58\": \"LABEL_58\",\n",
      "    \"59\": \"LABEL_59\",\n",
      "    \"60\": \"LABEL_60\",\n",
      "    \"61\": \"LABEL_61\",\n",
      "    \"62\": \"LABEL_62\",\n",
      "    \"63\": \"LABEL_63\",\n",
      "    \"64\": \"LABEL_64\",\n",
      "    \"65\": \"LABEL_65\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_10\": 10,\n",
      "    \"LABEL_11\": 11,\n",
      "    \"LABEL_12\": 12,\n",
      "    \"LABEL_13\": 13,\n",
      "    \"LABEL_14\": 14,\n",
      "    \"LABEL_15\": 15,\n",
      "    \"LABEL_16\": 16,\n",
      "    \"LABEL_17\": 17,\n",
      "    \"LABEL_18\": 18,\n",
      "    \"LABEL_19\": 19,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_20\": 20,\n",
      "    \"LABEL_21\": 21,\n",
      "    \"LABEL_22\": 22,\n",
      "    \"LABEL_23\": 23,\n",
      "    \"LABEL_24\": 24,\n",
      "    \"LABEL_25\": 25,\n",
      "    \"LABEL_26\": 26,\n",
      "    \"LABEL_27\": 27,\n",
      "    \"LABEL_28\": 28,\n",
      "    \"LABEL_29\": 29,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_30\": 30,\n",
      "    \"LABEL_31\": 31,\n",
      "    \"LABEL_32\": 32,\n",
      "    \"LABEL_33\": 33,\n",
      "    \"LABEL_34\": 34,\n",
      "    \"LABEL_35\": 35,\n",
      "    \"LABEL_36\": 36,\n",
      "    \"LABEL_37\": 37,\n",
      "    \"LABEL_38\": 38,\n",
      "    \"LABEL_39\": 39,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_40\": 40,\n",
      "    \"LABEL_41\": 41,\n",
      "    \"LABEL_42\": 42,\n",
      "    \"LABEL_43\": 43,\n",
      "    \"LABEL_44\": 44,\n",
      "    \"LABEL_45\": 45,\n",
      "    \"LABEL_46\": 46,\n",
      "    \"LABEL_47\": 47,\n",
      "    \"LABEL_48\": 48,\n",
      "    \"LABEL_49\": 49,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_50\": 50,\n",
      "    \"LABEL_51\": 51,\n",
      "    \"LABEL_52\": 52,\n",
      "    \"LABEL_53\": 53,\n",
      "    \"LABEL_54\": 54,\n",
      "    \"LABEL_55\": 55,\n",
      "    \"LABEL_56\": 56,\n",
      "    \"LABEL_57\": 57,\n",
      "    \"LABEL_58\": 58,\n",
      "    \"LABEL_59\": 59,\n",
      "    \"LABEL_6\": 6,\n",
      "    \"LABEL_60\": 60,\n",
      "    \"LABEL_61\": 61,\n",
      "    \"LABEL_62\": 62,\n",
      "    \"LABEL_63\": 63,\n",
      "    \"LABEL_64\": 64,\n",
      "    \"LABEL_65\": 65,\n",
      "    \"LABEL_7\": 7,\n",
      "    \"LABEL_8\": 8,\n",
      "    \"LABEL_9\": 9\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 64,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 5,\n",
      "  \"num_hidden_layers\": 3,\n",
      "  \"pad_token_id\": 2,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.21.3\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 2284\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/michaelginn/usp-mlm-genbench/resolve/main/pytorch_model.bin from cache at /Users/milesper/.cache/huggingface/transformers/d7e5230efe851bdf68f637461a225ebbce63c98853300cde5501f6d071197438.9cf0601a4c62d887f4b4f71aa6a8af6600da8c5ce6a0dacc3304f76c90864424\n",
      "Some weights of the model checkpoint at michaelginn/usp-mlm-genbench were not used when initializing RobertaForTokenClassification: ['lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at michaelginn/usp-mlm-genbench and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": "RobertaConfig {\n  \"_name_or_path\": \"michaelginn/usp-mlm-genbench\",\n  \"architectures\": [\n    \"RobertaForMaskedLM\"\n  ],\n  \"attention_probs_dropout_prob\": 0.1,\n  \"bos_token_id\": 0,\n  \"classifier_dropout\": null,\n  \"eos_token_id\": 2,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 100,\n  \"id2label\": {\n    \"0\": \"LABEL_0\",\n    \"1\": \"LABEL_1\",\n    \"2\": \"LABEL_2\",\n    \"3\": \"LABEL_3\",\n    \"4\": \"LABEL_4\",\n    \"5\": \"LABEL_5\",\n    \"6\": \"LABEL_6\",\n    \"7\": \"LABEL_7\",\n    \"8\": \"LABEL_8\",\n    \"9\": \"LABEL_9\",\n    \"10\": \"LABEL_10\",\n    \"11\": \"LABEL_11\",\n    \"12\": \"LABEL_12\",\n    \"13\": \"LABEL_13\",\n    \"14\": \"LABEL_14\",\n    \"15\": \"LABEL_15\",\n    \"16\": \"LABEL_16\",\n    \"17\": \"LABEL_17\",\n    \"18\": \"LABEL_18\",\n    \"19\": \"LABEL_19\",\n    \"20\": \"LABEL_20\",\n    \"21\": \"LABEL_21\",\n    \"22\": \"LABEL_22\",\n    \"23\": \"LABEL_23\",\n    \"24\": \"LABEL_24\",\n    \"25\": \"LABEL_25\",\n    \"26\": \"LABEL_26\",\n    \"27\": \"LABEL_27\",\n    \"28\": \"LABEL_28\",\n    \"29\": \"LABEL_29\",\n    \"30\": \"LABEL_30\",\n    \"31\": \"LABEL_31\",\n    \"32\": \"LABEL_32\",\n    \"33\": \"LABEL_33\",\n    \"34\": \"LABEL_34\",\n    \"35\": \"LABEL_35\",\n    \"36\": \"LABEL_36\",\n    \"37\": \"LABEL_37\",\n    \"38\": \"LABEL_38\",\n    \"39\": \"LABEL_39\",\n    \"40\": \"LABEL_40\",\n    \"41\": \"LABEL_41\",\n    \"42\": \"LABEL_42\",\n    \"43\": \"LABEL_43\",\n    \"44\": \"LABEL_44\",\n    \"45\": \"LABEL_45\",\n    \"46\": \"LABEL_46\",\n    \"47\": \"LABEL_47\",\n    \"48\": \"LABEL_48\",\n    \"49\": \"LABEL_49\",\n    \"50\": \"LABEL_50\",\n    \"51\": \"LABEL_51\",\n    \"52\": \"LABEL_52\",\n    \"53\": \"LABEL_53\",\n    \"54\": \"LABEL_54\",\n    \"55\": \"LABEL_55\",\n    \"56\": \"LABEL_56\",\n    \"57\": \"LABEL_57\",\n    \"58\": \"LABEL_58\",\n    \"59\": \"LABEL_59\",\n    \"60\": \"LABEL_60\",\n    \"61\": \"LABEL_61\",\n    \"62\": \"LABEL_62\",\n    \"63\": \"LABEL_63\",\n    \"64\": \"LABEL_64\",\n    \"65\": \"LABEL_65\"\n  },\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 3072,\n  \"label2id\": {\n    \"LABEL_0\": 0,\n    \"LABEL_1\": 1,\n    \"LABEL_10\": 10,\n    \"LABEL_11\": 11,\n    \"LABEL_12\": 12,\n    \"LABEL_13\": 13,\n    \"LABEL_14\": 14,\n    \"LABEL_15\": 15,\n    \"LABEL_16\": 16,\n    \"LABEL_17\": 17,\n    \"LABEL_18\": 18,\n    \"LABEL_19\": 19,\n    \"LABEL_2\": 2,\n    \"LABEL_20\": 20,\n    \"LABEL_21\": 21,\n    \"LABEL_22\": 22,\n    \"LABEL_23\": 23,\n    \"LABEL_24\": 24,\n    \"LABEL_25\": 25,\n    \"LABEL_26\": 26,\n    \"LABEL_27\": 27,\n    \"LABEL_28\": 28,\n    \"LABEL_29\": 29,\n    \"LABEL_3\": 3,\n    \"LABEL_30\": 30,\n    \"LABEL_31\": 31,\n    \"LABEL_32\": 32,\n    \"LABEL_33\": 33,\n    \"LABEL_34\": 34,\n    \"LABEL_35\": 35,\n    \"LABEL_36\": 36,\n    \"LABEL_37\": 37,\n    \"LABEL_38\": 38,\n    \"LABEL_39\": 39,\n    \"LABEL_4\": 4,\n    \"LABEL_40\": 40,\n    \"LABEL_41\": 41,\n    \"LABEL_42\": 42,\n    \"LABEL_43\": 43,\n    \"LABEL_44\": 44,\n    \"LABEL_45\": 45,\n    \"LABEL_46\": 46,\n    \"LABEL_47\": 47,\n    \"LABEL_48\": 48,\n    \"LABEL_49\": 49,\n    \"LABEL_5\": 5,\n    \"LABEL_50\": 50,\n    \"LABEL_51\": 51,\n    \"LABEL_52\": 52,\n    \"LABEL_53\": 53,\n    \"LABEL_54\": 54,\n    \"LABEL_55\": 55,\n    \"LABEL_56\": 56,\n    \"LABEL_57\": 57,\n    \"LABEL_58\": 58,\n    \"LABEL_59\": 59,\n    \"LABEL_6\": 6,\n    \"LABEL_60\": 60,\n    \"LABEL_61\": 61,\n    \"LABEL_62\": 62,\n    \"LABEL_63\": 63,\n    \"LABEL_64\": 64,\n    \"LABEL_65\": 65,\n    \"LABEL_7\": 7,\n    \"LABEL_8\": 8,\n    \"LABEL_9\": 9\n  },\n  \"layer_norm_eps\": 1e-12,\n  \"max_position_embeddings\": 64,\n  \"model_type\": \"roberta\",\n  \"num_attention_heads\": 5,\n  \"num_hidden_layers\": 3,\n  \"pad_token_id\": 2,\n  \"position_embedding_type\": \"absolute\",\n  \"torch_dtype\": \"float32\",\n  \"transformers_version\": \"4.21.3\",\n  \"type_vocab_size\": 2,\n  \"use_cache\": true,\n  \"vocab_size\": 2284\n}"
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AutoModelForTokenClassification.from_pretrained(\"michaelginn/usp-mlm-genbench\",\n",
    "                                                num_labels=len(glosses)).config"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-26T16:57:16.828075Z",
     "start_time": "2023-08-26T16:57:16.329571Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/michaelginn/usp-lang-relative_key_query-micro/resolve/main/config.json from cache at /Users/milesper/.cache/huggingface/transformers/ea8855f043b5a1f8318bf563a18468cfd79684505aa12404edc1df9fc90d1bcc.b852993b5a3265e4f22ced7049b0f3bb4e8e146614e7c4e8bf50c8adb05e8907\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"michaelginn/usp-lang-relative_key_query-micro\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 100,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\",\n",
      "    \"7\": \"LABEL_7\",\n",
      "    \"8\": \"LABEL_8\",\n",
      "    \"9\": \"LABEL_9\",\n",
      "    \"10\": \"LABEL_10\",\n",
      "    \"11\": \"LABEL_11\",\n",
      "    \"12\": \"LABEL_12\",\n",
      "    \"13\": \"LABEL_13\",\n",
      "    \"14\": \"LABEL_14\",\n",
      "    \"15\": \"LABEL_15\",\n",
      "    \"16\": \"LABEL_16\",\n",
      "    \"17\": \"LABEL_17\",\n",
      "    \"18\": \"LABEL_18\",\n",
      "    \"19\": \"LABEL_19\",\n",
      "    \"20\": \"LABEL_20\",\n",
      "    \"21\": \"LABEL_21\",\n",
      "    \"22\": \"LABEL_22\",\n",
      "    \"23\": \"LABEL_23\",\n",
      "    \"24\": \"LABEL_24\",\n",
      "    \"25\": \"LABEL_25\",\n",
      "    \"26\": \"LABEL_26\",\n",
      "    \"27\": \"LABEL_27\",\n",
      "    \"28\": \"LABEL_28\",\n",
      "    \"29\": \"LABEL_29\",\n",
      "    \"30\": \"LABEL_30\",\n",
      "    \"31\": \"LABEL_31\",\n",
      "    \"32\": \"LABEL_32\",\n",
      "    \"33\": \"LABEL_33\",\n",
      "    \"34\": \"LABEL_34\",\n",
      "    \"35\": \"LABEL_35\",\n",
      "    \"36\": \"LABEL_36\",\n",
      "    \"37\": \"LABEL_37\",\n",
      "    \"38\": \"LABEL_38\",\n",
      "    \"39\": \"LABEL_39\",\n",
      "    \"40\": \"LABEL_40\",\n",
      "    \"41\": \"LABEL_41\",\n",
      "    \"42\": \"LABEL_42\",\n",
      "    \"43\": \"LABEL_43\",\n",
      "    \"44\": \"LABEL_44\",\n",
      "    \"45\": \"LABEL_45\",\n",
      "    \"46\": \"LABEL_46\",\n",
      "    \"47\": \"LABEL_47\",\n",
      "    \"48\": \"LABEL_48\",\n",
      "    \"49\": \"LABEL_49\",\n",
      "    \"50\": \"LABEL_50\",\n",
      "    \"51\": \"LABEL_51\",\n",
      "    \"52\": \"LABEL_52\",\n",
      "    \"53\": \"LABEL_53\",\n",
      "    \"54\": \"LABEL_54\",\n",
      "    \"55\": \"LABEL_55\",\n",
      "    \"56\": \"LABEL_56\",\n",
      "    \"57\": \"LABEL_57\",\n",
      "    \"58\": \"LABEL_58\",\n",
      "    \"59\": \"LABEL_59\",\n",
      "    \"60\": \"LABEL_60\",\n",
      "    \"61\": \"LABEL_61\",\n",
      "    \"62\": \"LABEL_62\",\n",
      "    \"63\": \"LABEL_63\",\n",
      "    \"64\": \"LABEL_64\",\n",
      "    \"65\": \"LABEL_65\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_10\": 10,\n",
      "    \"LABEL_11\": 11,\n",
      "    \"LABEL_12\": 12,\n",
      "    \"LABEL_13\": 13,\n",
      "    \"LABEL_14\": 14,\n",
      "    \"LABEL_15\": 15,\n",
      "    \"LABEL_16\": 16,\n",
      "    \"LABEL_17\": 17,\n",
      "    \"LABEL_18\": 18,\n",
      "    \"LABEL_19\": 19,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_20\": 20,\n",
      "    \"LABEL_21\": 21,\n",
      "    \"LABEL_22\": 22,\n",
      "    \"LABEL_23\": 23,\n",
      "    \"LABEL_24\": 24,\n",
      "    \"LABEL_25\": 25,\n",
      "    \"LABEL_26\": 26,\n",
      "    \"LABEL_27\": 27,\n",
      "    \"LABEL_28\": 28,\n",
      "    \"LABEL_29\": 29,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_30\": 30,\n",
      "    \"LABEL_31\": 31,\n",
      "    \"LABEL_32\": 32,\n",
      "    \"LABEL_33\": 33,\n",
      "    \"LABEL_34\": 34,\n",
      "    \"LABEL_35\": 35,\n",
      "    \"LABEL_36\": 36,\n",
      "    \"LABEL_37\": 37,\n",
      "    \"LABEL_38\": 38,\n",
      "    \"LABEL_39\": 39,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_40\": 40,\n",
      "    \"LABEL_41\": 41,\n",
      "    \"LABEL_42\": 42,\n",
      "    \"LABEL_43\": 43,\n",
      "    \"LABEL_44\": 44,\n",
      "    \"LABEL_45\": 45,\n",
      "    \"LABEL_46\": 46,\n",
      "    \"LABEL_47\": 47,\n",
      "    \"LABEL_48\": 48,\n",
      "    \"LABEL_49\": 49,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_50\": 50,\n",
      "    \"LABEL_51\": 51,\n",
      "    \"LABEL_52\": 52,\n",
      "    \"LABEL_53\": 53,\n",
      "    \"LABEL_54\": 54,\n",
      "    \"LABEL_55\": 55,\n",
      "    \"LABEL_56\": 56,\n",
      "    \"LABEL_57\": 57,\n",
      "    \"LABEL_58\": 58,\n",
      "    \"LABEL_59\": 59,\n",
      "    \"LABEL_6\": 6,\n",
      "    \"LABEL_60\": 60,\n",
      "    \"LABEL_61\": 61,\n",
      "    \"LABEL_62\": 62,\n",
      "    \"LABEL_63\": 63,\n",
      "    \"LABEL_64\": 64,\n",
      "    \"LABEL_65\": 65,\n",
      "    \"LABEL_7\": 7,\n",
      "    \"LABEL_8\": 8,\n",
      "    \"LABEL_9\": 9\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 64,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 5,\n",
      "  \"num_hidden_layers\": 3,\n",
      "  \"pad_token_id\": 2,\n",
      "  \"position_embedding_type\": \"relative_key_query\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.21.3\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 2284\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/michaelginn/usp-lang-relative_key_query-micro/resolve/main/pytorch_model.bin from cache at /Users/milesper/.cache/huggingface/transformers/e67845baf4f6715fb95f5e2b09aa26a5757dd33b852ca84155fc8c98262eae15.0d33640f97dee3819321fdbf0c68d718f1341399419411d4538f408593a73a5b\n",
      "Some weights of the model checkpoint at michaelginn/usp-lang-relative_key_query-micro were not used when initializing RobertaForTokenClassification: ['lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at michaelginn/usp-lang-relative_key_query-micro and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": "RobertaConfig {\n  \"_name_or_path\": \"michaelginn/usp-lang-relative_key_query-micro\",\n  \"architectures\": [\n    \"RobertaForMaskedLM\"\n  ],\n  \"attention_probs_dropout_prob\": 0.1,\n  \"bos_token_id\": 0,\n  \"classifier_dropout\": null,\n  \"eos_token_id\": 2,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 100,\n  \"id2label\": {\n    \"0\": \"LABEL_0\",\n    \"1\": \"LABEL_1\",\n    \"2\": \"LABEL_2\",\n    \"3\": \"LABEL_3\",\n    \"4\": \"LABEL_4\",\n    \"5\": \"LABEL_5\",\n    \"6\": \"LABEL_6\",\n    \"7\": \"LABEL_7\",\n    \"8\": \"LABEL_8\",\n    \"9\": \"LABEL_9\",\n    \"10\": \"LABEL_10\",\n    \"11\": \"LABEL_11\",\n    \"12\": \"LABEL_12\",\n    \"13\": \"LABEL_13\",\n    \"14\": \"LABEL_14\",\n    \"15\": \"LABEL_15\",\n    \"16\": \"LABEL_16\",\n    \"17\": \"LABEL_17\",\n    \"18\": \"LABEL_18\",\n    \"19\": \"LABEL_19\",\n    \"20\": \"LABEL_20\",\n    \"21\": \"LABEL_21\",\n    \"22\": \"LABEL_22\",\n    \"23\": \"LABEL_23\",\n    \"24\": \"LABEL_24\",\n    \"25\": \"LABEL_25\",\n    \"26\": \"LABEL_26\",\n    \"27\": \"LABEL_27\",\n    \"28\": \"LABEL_28\",\n    \"29\": \"LABEL_29\",\n    \"30\": \"LABEL_30\",\n    \"31\": \"LABEL_31\",\n    \"32\": \"LABEL_32\",\n    \"33\": \"LABEL_33\",\n    \"34\": \"LABEL_34\",\n    \"35\": \"LABEL_35\",\n    \"36\": \"LABEL_36\",\n    \"37\": \"LABEL_37\",\n    \"38\": \"LABEL_38\",\n    \"39\": \"LABEL_39\",\n    \"40\": \"LABEL_40\",\n    \"41\": \"LABEL_41\",\n    \"42\": \"LABEL_42\",\n    \"43\": \"LABEL_43\",\n    \"44\": \"LABEL_44\",\n    \"45\": \"LABEL_45\",\n    \"46\": \"LABEL_46\",\n    \"47\": \"LABEL_47\",\n    \"48\": \"LABEL_48\",\n    \"49\": \"LABEL_49\",\n    \"50\": \"LABEL_50\",\n    \"51\": \"LABEL_51\",\n    \"52\": \"LABEL_52\",\n    \"53\": \"LABEL_53\",\n    \"54\": \"LABEL_54\",\n    \"55\": \"LABEL_55\",\n    \"56\": \"LABEL_56\",\n    \"57\": \"LABEL_57\",\n    \"58\": \"LABEL_58\",\n    \"59\": \"LABEL_59\",\n    \"60\": \"LABEL_60\",\n    \"61\": \"LABEL_61\",\n    \"62\": \"LABEL_62\",\n    \"63\": \"LABEL_63\",\n    \"64\": \"LABEL_64\",\n    \"65\": \"LABEL_65\"\n  },\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 3072,\n  \"label2id\": {\n    \"LABEL_0\": 0,\n    \"LABEL_1\": 1,\n    \"LABEL_10\": 10,\n    \"LABEL_11\": 11,\n    \"LABEL_12\": 12,\n    \"LABEL_13\": 13,\n    \"LABEL_14\": 14,\n    \"LABEL_15\": 15,\n    \"LABEL_16\": 16,\n    \"LABEL_17\": 17,\n    \"LABEL_18\": 18,\n    \"LABEL_19\": 19,\n    \"LABEL_2\": 2,\n    \"LABEL_20\": 20,\n    \"LABEL_21\": 21,\n    \"LABEL_22\": 22,\n    \"LABEL_23\": 23,\n    \"LABEL_24\": 24,\n    \"LABEL_25\": 25,\n    \"LABEL_26\": 26,\n    \"LABEL_27\": 27,\n    \"LABEL_28\": 28,\n    \"LABEL_29\": 29,\n    \"LABEL_3\": 3,\n    \"LABEL_30\": 30,\n    \"LABEL_31\": 31,\n    \"LABEL_32\": 32,\n    \"LABEL_33\": 33,\n    \"LABEL_34\": 34,\n    \"LABEL_35\": 35,\n    \"LABEL_36\": 36,\n    \"LABEL_37\": 37,\n    \"LABEL_38\": 38,\n    \"LABEL_39\": 39,\n    \"LABEL_4\": 4,\n    \"LABEL_40\": 40,\n    \"LABEL_41\": 41,\n    \"LABEL_42\": 42,\n    \"LABEL_43\": 43,\n    \"LABEL_44\": 44,\n    \"LABEL_45\": 45,\n    \"LABEL_46\": 46,\n    \"LABEL_47\": 47,\n    \"LABEL_48\": 48,\n    \"LABEL_49\": 49,\n    \"LABEL_5\": 5,\n    \"LABEL_50\": 50,\n    \"LABEL_51\": 51,\n    \"LABEL_52\": 52,\n    \"LABEL_53\": 53,\n    \"LABEL_54\": 54,\n    \"LABEL_55\": 55,\n    \"LABEL_56\": 56,\n    \"LABEL_57\": 57,\n    \"LABEL_58\": 58,\n    \"LABEL_59\": 59,\n    \"LABEL_6\": 6,\n    \"LABEL_60\": 60,\n    \"LABEL_61\": 61,\n    \"LABEL_62\": 62,\n    \"LABEL_63\": 63,\n    \"LABEL_64\": 64,\n    \"LABEL_65\": 65,\n    \"LABEL_7\": 7,\n    \"LABEL_8\": 8,\n    \"LABEL_9\": 9\n  },\n  \"layer_norm_eps\": 1e-12,\n  \"max_position_embeddings\": 64,\n  \"model_type\": \"roberta\",\n  \"num_attention_heads\": 5,\n  \"num_hidden_layers\": 3,\n  \"pad_token_id\": 2,\n  \"position_embedding_type\": \"relative_key_query\",\n  \"torch_dtype\": \"float32\",\n  \"transformers_version\": \"4.21.3\",\n  \"type_vocab_size\": 2,\n  \"use_cache\": true,\n  \"vocab_size\": 2284\n}"
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AutoModelForTokenClassification.from_pretrained(\"michaelginn/usp-lang-relative_key_query-micro\",\n",
    "                                                num_labels=len(glosses)).config"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-26T16:52:03.606872Z",
     "start_time": "2023-08-26T16:52:02.577997Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "outputs": [
    {
     "data": {
      "text/plain": "2280"
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_vocab)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-26T16:51:21.562303Z",
     "start_time": "2023-08-26T16:51:21.532475Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDS [[43  1 26 ... 43 43 43]\n",
      " [14 43 43 ... 43 43 43]\n",
      " [14 43 43 ... 43 43 43]\n",
      " ...\n",
      " [54  1 43 ... 43 43 43]\n",
      " [43  1 53 ... 43 43 43]\n",
      " [39 14  1 ... 43 43 43]]\n",
      "LABELS [[  54    1   26 ... -100 -100 -100]\n",
      " [   9   43 -100 ... -100 -100 -100]\n",
      " [   9   43 -100 ... -100 -100 -100]\n",
      " ...\n",
      " [  57    1   50 ... -100 -100 -100]\n",
      " [  43    1   53 ... -100 -100 -100]\n",
      " [   3   53    1 ... -100 -100 -100]]\n",
      "(4256, 64)\n",
      "Preds:\t ['S', '[SEP]', 'INC', 'VT', 'E3S', '[SEP]', 'INC', 'VT', 'VT', '[SEP]', 'PRON']\n",
      "Labels:\t ['ADV', '[SEP]', 'INC', 'VT', 'SC', '[SEP]', 'INC', 'E1S', 'VI', '[SEP]', 'PRON']\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[43,  1, 26, ..., 43, 43, 43],\n       [14, 43, 43, ..., 43, 43, 43],\n       [14, 43, 43, ..., 43, 43, 43],\n       ...,\n       [54,  1, 43, ..., 43, 43, 43],\n       [43,  1, 53, ..., 43, 43, 43],\n       [39, 14,  1, ..., 43, 43, 43]])"
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set don't have a corresponding argument in `RobertaForTokenClassification.forward` and have been ignored: translation, morphemes, transcription, segmentation, glosses. If translation, morphemes, transcription, segmentation, glosses are not expected by `RobertaForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 4256\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDS [[43  1 26 ... 43 43 43]\n",
      " [14 43 43 ... 43 43 43]\n",
      " [14 43 43 ... 43 43 43]\n",
      " ...\n",
      " [54  1 43 ... 43 43 43]\n",
      " [43  1 53 ... 43 43 43]\n",
      " [39 14  1 ... 43 43 43]]\n",
      "LABELS [[  54    1   26 ... -100 -100 -100]\n",
      " [   9   43 -100 ... -100 -100 -100]\n",
      " [   9   43 -100 ... -100 -100 -100]\n",
      " ...\n",
      " [  57    1   50 ... -100 -100 -100]\n",
      " [  43    1   53 ... -100 -100 -100]\n",
      " [   3   53    1 ... -100 -100 -100]]\n",
      "(4256, 64)\n",
      "Preds:\t ['S', '[SEP]', 'INC', 'VT', 'E3S', '[SEP]', 'INC', 'VT', 'VT', '[SEP]', 'PRON']\n",
      "Labels:\t ['ADV', '[SEP]', 'INC', 'VT', 'SC', '[SEP]', 'INC', 'E1S', 'VI', '[SEP]', 'PRON']\n"
     ]
    }
   ],
   "source": [
    "preds = trainer.predict(dataset['eval_OOD']).predictions"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-27T02:37:46.883158Z",
     "start_time": "2023-08-27T02:37:40.014777Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[43,  1, 26, ..., 43, 43, 43],\n       [14, 43, 43, ..., 43, 43, 43],\n       [14, 43, 43, ..., 43, 43, 43],\n       ...,\n       [54,  1, 43, ..., 43, 43, 43],\n       [43,  1, 53, ..., 43, 43, 43],\n       [39, 14,  1, ..., 43, 43, 43]])"
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-27T02:37:46.887198Z",
     "start_time": "2023-08-27T02:37:46.883713Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "outputs": [],
   "source": [
    "decoded_preds = [[glosses[index] for index in pred_seq if len(glosses) > index >= 0] for pred_seq in preds]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-27T02:38:24.345734Z",
     "start_time": "2023-08-27T02:38:24.305898Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S', '[SEP]', 'INC', 'VT', 'E3S', '[SEP]', 'INC', 'VT', 'VT', '[SEP]', 'PRON', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S']\n"
     ]
    }
   ],
   "source": [
    "print(decoded_preds[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-27T02:38:41.184207Z",
     "start_time": "2023-08-27T02:38:41.155734Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "antonses chib'aanik tanb'ij iin.\n"
     ]
    }
   ],
   "source": [
    "print(dataset['eval_OOD'][0]['transcription'])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-27T02:42:18.494011Z",
     "start_time": "2023-08-27T02:42:18.454459Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "outputs": [
    {
     "data": {
      "text/plain": "['antonses',\n '[SEP]',\n 'chi',\n \"b'an\",\n 'ik',\n '[SEP]',\n 't',\n 'an',\n \"b'ij\",\n '[SEP]',\n 'iin']"
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_ood[0].morphemes()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-27T02:47:55.087670Z",
     "start_time": "2023-08-27T02:47:55.076530Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "853"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_ood)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-27T22:38:11.551800Z",
     "start_time": "2023-08-27T22:38:11.535168Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "test_ood = load_data_file(\"../data/GenBench/test_OOD\")\n",
    "test_id = load_data_file(\"../data/GenBench/test_ID\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-27T22:37:55.142137Z",
     "start_time": "2023-08-27T22:37:55.122105Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['transcription', 'translation', 'glosses', 'segmentation', 'morphemes', 'input_ids', 'attention_mask', 'labels'],\n        num_rows: 5843\n    })\n    advice: Dataset({\n        features: ['transcription', 'translation', 'glosses', 'segmentation', 'morphemes', 'input_ids', 'attention_mask', 'labels'],\n        num_rows: 612\n    })\n    history: Dataset({\n        features: ['transcription', 'translation', 'glosses', 'segmentation', 'morphemes', 'input_ids', 'attention_mask', 'labels'],\n        num_rows: 1334\n    })\n    personal: Dataset({\n        features: ['transcription', 'translation', 'glosses', 'segmentation', 'morphemes', 'input_ids', 'attention_mask', 'labels'],\n        num_rows: 3644\n    })\n    eval_OOD: Dataset({\n        features: ['transcription', 'translation', 'glosses', 'segmentation', 'morphemes', 'input_ids', 'attention_mask', 'labels'],\n        num_rows: 481\n    })\n    eval_ID: Dataset({\n        features: ['transcription', 'translation', 'glosses', 'segmentation', 'morphemes', 'input_ids', 'attention_mask', 'labels'],\n        num_rows: 2219\n    })\n    dev: Dataset({\n        features: ['transcription', 'translation', 'glosses', 'segmentation', 'morphemes', 'input_ids', 'attention_mask', 'labels'],\n        num_rows: 1334\n    })\n})"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-28T00:22:28.108221Z",
     "start_time": "2023-08-28T00:22:28.079684Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from data_handling import write_igt, load_data_file\n",
    "import random\n",
    "\n",
    "story = load_data_file(\"../data/GenBench/categories/story\")\n",
    "advice = load_data_file(\"../data/GenBench/categories/advice\")\n",
    "history = load_data_file(\"../data/GenBench/categories/history\")\n",
    "personal = load_data_file(\"../data/GenBench/categories/personal\")\n",
    "\n",
    "id_data = story + personal\n",
    "ood_data = advice + history\n",
    "\n",
    "random.shuffle(id_data)\n",
    "random.shuffle(ood_data)\n",
    "\n",
    "count_ood = int(len(ood_data) / 2)\n",
    "\n",
    "eval_ood = ood_data[:count_ood]\n",
    "test_ood = ood_data[count_ood:]\n",
    "\n",
    "eval_id = id_data[:count_ood]\n",
    "train = id_data[count_ood:]\n",
    "\n",
    "write_igt(eval_ood, '../data/GenBench/eval_ood.txt')\n",
    "write_igt(eval_id, '../data/GenBench/eval_id.txt')\n",
    "write_igt(test_ood, '../data/GenBench/test_ood.txt')\n",
    "write_igt(train, '../data/GenBench/train.txt')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-28T00:33:06.225669Z",
     "start_time": "2023-08-28T00:33:03.065165Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "973"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(eval_ood)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-28T00:39:14.130874Z",
     "start_time": "2023-08-28T00:39:14.116106Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
