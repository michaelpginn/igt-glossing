{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 213,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 10099 train lines and 1334 eval lines\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/10099 [00:00<?, ?ex/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a63a820e217c4f798cb0a39ab5c499e4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1334 [00:00<?, ?ex/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "120c2fc02b304448bd4ef1d22018aed3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from data import load_data_file, create_vocab, prepare_dataset, create_gloss_vocab\n",
    "from uspanteko_morphology import morphology\n",
    "from tokenizer import WordLevelTokenizer\n",
    "from datasets import DatasetDict\n",
    "\n",
    "train_data = load_data_file(\"../data/GenBench/story_advice_personal\")\n",
    "eval_data = load_data_file(\"../data/GenBench/history\")\n",
    "\n",
    "print(f\"Loaded {len(train_data)} train lines and {len(eval_data)} eval lines\")\n",
    "\n",
    "MODEL_INPUT_LENGTH = 64\n",
    "device = 'cpu'\n",
    "\n",
    "train_vocab = create_vocab([line.morphemes() for line in train_data], threshold=1)\n",
    "tokenizer = WordLevelTokenizer(vocab=train_vocab, model_max_length=MODEL_INPUT_LENGTH)\n",
    "\n",
    "glosses = create_gloss_vocab(morphology)\n",
    "\n",
    "dataset = DatasetDict()\n",
    "\n",
    "dataset['train'] = prepare_dataset(data=train_data, tokenizer=tokenizer, labels=glosses, device=device)\n",
    "dataset['dev'] = prepare_dataset(data=eval_data, tokenizer=tokenizer, labels=glosses, device=device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-25T21:39:59.487536Z",
     "start_time": "2023-08-25T21:39:56.282993Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "outputs": [],
   "source": [
    "from transformers import AutoModelForTokenClassification\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"./full-flat-1\",\n",
    "                                                        num_labels=len(glosses))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-25T21:41:12.977575Z",
     "start_time": "2023-08-25T21:41:12.929811Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating trainer...\n"
     ]
    }
   ],
   "source": [
    "from finetune_token_classifier import create_trainer\n",
    "\n",
    "trainer = create_trainer(model, dataset=dataset, tokenizer=tokenizer, labels=glosses, batch_size=64,\n",
    "                         max_epochs=600, report_to=\"none\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-25T21:42:20.688904Z",
     "start_time": "2023-08-25T21:42:20.193937Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForTokenClassification.forward` and have been ignored: translation, morphemes, transcription, segmentation, glosses. If translation, morphemes, transcription, segmentation, glosses are not expected by `RobertaForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1334\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='1' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 1/21 : < :]\n    </div>\n    "
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDS [[36  1 50 ... 65 65 65]\n",
      " [38  1 53 ...  9  9  9]\n",
      " [40  1 40 ...  9  9  9]\n",
      " ...\n",
      " [42  1 39 ... 34 34 34]\n",
      " [54  1 57 ...  0  0  0]\n",
      " [37 44  1 ...  9  9  9]]\n",
      "LABELS [[  36    1   50 ... -100 -100 -100]\n",
      " [  45    1   53 ... -100 -100 -100]\n",
      " [  40    1   43 ... -100 -100 -100]\n",
      " ...\n",
      " [  42    1   39 ... -100 -100 -100]\n",
      " [  54    1   57 ... -100 -100 -100]\n",
      " [  37   44    1 ... -100 -100 -100]]\n",
      "(1334, 64)\n",
      "Preds:\t ['EXS', '[SEP]', 'NUM', '[SEP]', 'NOM', '[SEP]', 'NOM']\n",
      "Labels:\t ['EXS', '[SEP]', 'NUM', '[SEP]', 'S', '[SEP]', 'DEM']\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'eval_loss': 0.4575164318084717,\n 'eval_average_accuracy': 0.8228964872644873,\n 'eval_accuracy': 0.8245183458093017,\n 'eval_runtime': 2.0218,\n 'eval_samples_per_second': 659.803,\n 'eval_steps_per_second': 10.387}"
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-25T21:42:51.501579Z",
     "start_time": "2023-08-25T21:42:49.472451Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
