{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d3e3a82-ad41-4371-92e6-cdf1ea241722",
   "metadata": {},
   "source": [
    "# Evalutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02512dc8-f550-4338-ae06-9be10ea3cf4a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from data_handling import write_igt, load_data_file\n",
    "import random\n",
    "\n",
    "story = load_data_file(\"../data/GenBench/categories/story\")\n",
    "advice = load_data_file(\"../data/GenBench/categories/advice\")\n",
    "history = load_data_file(\"../data/GenBench/categories/history\")\n",
    "personal = load_data_file(\"../data/GenBench/categories/personal\")\n",
    "\n",
    "id_data = story + history\n",
    "ood_data = advice + personal\n",
    "\n",
    "random.seed(1)\n",
    "random.shuffle(id_data)\n",
    "random.shuffle(ood_data)\n",
    "\n",
    "count_ood = int(len(ood_data) / 2)\n",
    "\n",
    "eval_ood = ood_data[:count_ood]\n",
    "test_ood = ood_data[count_ood:]\n",
    "\n",
    "eval_id = id_data[:count_ood]\n",
    "train = id_data[count_ood:]\n",
    "\n",
    "write_igt(eval_ood, '../data/GenBench/eval_ood.txt')\n",
    "write_igt(eval_id, '../data/GenBench/eval_id.txt')\n",
    "write_igt(test_ood, '../data/GenBench/test_ood.txt')\n",
    "write_igt(train, '../data/GenBench/train.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7591b2c-88a1-41bd-90d2-4bc277476f87",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8c53614816346ff8981997ea33ce439",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5049 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be79fa4cf32f41e2909a9bb22a0264c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2128 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eeaa26887b8c4f45a296c1237bd23b82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2128 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3591c668ca5648e8a09e49b9cb0d549b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2128 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from data_handling import create_vocab, prepare_dataset, create_gloss_vocab\n",
    "from uspanteko_morphology import morphology\n",
    "from tokenizer import WordLevelTokenizer\n",
    "from datasets import DatasetDict\n",
    "\n",
    "MODEL_INPUT_LENGTH = 64\n",
    "device = 'mps'\n",
    "\n",
    "train_vocab = create_vocab([line.morphemes() for line in train], threshold=1)\n",
    "tokenizer = WordLevelTokenizer(vocab=train_vocab, model_max_length=MODEL_INPUT_LENGTH)\n",
    "glosses = create_gloss_vocab(morphology)\n",
    "\n",
    "dataset = DatasetDict()\n",
    "dataset['train'] = prepare_dataset(data=train, tokenizer=tokenizer, labels=glosses, device=device)\n",
    "dataset['dev'] = prepare_dataset(data=eval_id, tokenizer=tokenizer, labels=glosses, device=device)\n",
    "dataset['dev_OOD'] = prepare_dataset(data=eval_ood, tokenizer=tokenizer, labels=glosses, device=device)\n",
    "dataset['test'] = prepare_dataset(data=test_ood, tokenizer=tokenizer, labels=glosses, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6e07668-ef95-4745-8d89-e8010eb53b11",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForMaskedLM.forward` and have been ignored: translation, glosses, transcription, morphemes, segmentation. If translation, glosses, transcription, morphemes, segmentation are not expected by `RobertaForMaskedLM.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2128\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='68' max='34' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [34/34 00:13]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmichael-ginn\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.9 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/milesper/Documents/Research/TaxoMorph/src/wandb/run-20230830_220246-2m5eogqd</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/michael-ginn/huggingface/runs/2m5eogqd\" target=\"_blank\">../training-checkpoints</a></strong> to <a href=\"https://wandb.ai/michael-ginn/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForMaskedLM.forward` and have been ignored: translation, glosses, transcription, morphemes, segmentation. If translation, glosses, transcription, morphemes, segmentation are not expected by `RobertaForMaskedLM.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2128\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity (id): 77.78\n",
      "Perplexity (ood): 94.03\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments, DataCollatorForLanguageModeling, AutoModelForMaskedLM\n",
    "import math\n",
    "\n",
    "model = AutoModelForMaskedLM.from_pretrained(\"../models/usp-mlm-absolute-micro\")\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 50\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm_probability=0.15, return_tensors=\"pt\")\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=f\"../training-checkpoints\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    gradient_accumulation_steps=3,\n",
    "    weight_decay=0.01,\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=EPOCHS,\n",
    ")\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=dataset['train'],\n",
    "    eval_dataset=dataset['dev'],\n",
    "    data_collator=data_collator\n",
    ")\n",
    "\n",
    "\n",
    "eval_results = trainer.evaluate(dataset['dev'])\n",
    "print(f\"Perplexity (id): {math.exp(eval_results['eval_loss']):.2f}\")\n",
    "\n",
    "eval_results = trainer.evaluate(dataset['dev_OOD'])\n",
    "print(f\"Perplexity (ood): {math.exp(eval_results['eval_loss']):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1693f03c-4ff3-4f0f-bd09-de0a4c062fa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file ../models/full-flat-1-finetune-0.0wd-0.25itps-it2/config.json\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"../models/full-flat-1-finetune-0.0wd-0.25itps-it2\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForTokenClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 100,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\",\n",
      "    \"7\": \"LABEL_7\",\n",
      "    \"8\": \"LABEL_8\",\n",
      "    \"9\": \"LABEL_9\",\n",
      "    \"10\": \"LABEL_10\",\n",
      "    \"11\": \"LABEL_11\",\n",
      "    \"12\": \"LABEL_12\",\n",
      "    \"13\": \"LABEL_13\",\n",
      "    \"14\": \"LABEL_14\",\n",
      "    \"15\": \"LABEL_15\",\n",
      "    \"16\": \"LABEL_16\",\n",
      "    \"17\": \"LABEL_17\",\n",
      "    \"18\": \"LABEL_18\",\n",
      "    \"19\": \"LABEL_19\",\n",
      "    \"20\": \"LABEL_20\",\n",
      "    \"21\": \"LABEL_21\",\n",
      "    \"22\": \"LABEL_22\",\n",
      "    \"23\": \"LABEL_23\",\n",
      "    \"24\": \"LABEL_24\",\n",
      "    \"25\": \"LABEL_25\",\n",
      "    \"26\": \"LABEL_26\",\n",
      "    \"27\": \"LABEL_27\",\n",
      "    \"28\": \"LABEL_28\",\n",
      "    \"29\": \"LABEL_29\",\n",
      "    \"30\": \"LABEL_30\",\n",
      "    \"31\": \"LABEL_31\",\n",
      "    \"32\": \"LABEL_32\",\n",
      "    \"33\": \"LABEL_33\",\n",
      "    \"34\": \"LABEL_34\",\n",
      "    \"35\": \"LABEL_35\",\n",
      "    \"36\": \"LABEL_36\",\n",
      "    \"37\": \"LABEL_37\",\n",
      "    \"38\": \"LABEL_38\",\n",
      "    \"39\": \"LABEL_39\",\n",
      "    \"40\": \"LABEL_40\",\n",
      "    \"41\": \"LABEL_41\",\n",
      "    \"42\": \"LABEL_42\",\n",
      "    \"43\": \"LABEL_43\",\n",
      "    \"44\": \"LABEL_44\",\n",
      "    \"45\": \"LABEL_45\",\n",
      "    \"46\": \"LABEL_46\",\n",
      "    \"47\": \"LABEL_47\",\n",
      "    \"48\": \"LABEL_48\",\n",
      "    \"49\": \"LABEL_49\",\n",
      "    \"50\": \"LABEL_50\",\n",
      "    \"51\": \"LABEL_51\",\n",
      "    \"52\": \"LABEL_52\",\n",
      "    \"53\": \"LABEL_53\",\n",
      "    \"54\": \"LABEL_54\",\n",
      "    \"55\": \"LABEL_55\",\n",
      "    \"56\": \"LABEL_56\",\n",
      "    \"57\": \"LABEL_57\",\n",
      "    \"58\": \"LABEL_58\",\n",
      "    \"59\": \"LABEL_59\",\n",
      "    \"60\": \"LABEL_60\",\n",
      "    \"61\": \"LABEL_61\",\n",
      "    \"62\": \"LABEL_62\",\n",
      "    \"63\": \"LABEL_63\",\n",
      "    \"64\": \"LABEL_64\",\n",
      "    \"65\": \"LABEL_65\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_10\": 10,\n",
      "    \"LABEL_11\": 11,\n",
      "    \"LABEL_12\": 12,\n",
      "    \"LABEL_13\": 13,\n",
      "    \"LABEL_14\": 14,\n",
      "    \"LABEL_15\": 15,\n",
      "    \"LABEL_16\": 16,\n",
      "    \"LABEL_17\": 17,\n",
      "    \"LABEL_18\": 18,\n",
      "    \"LABEL_19\": 19,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_20\": 20,\n",
      "    \"LABEL_21\": 21,\n",
      "    \"LABEL_22\": 22,\n",
      "    \"LABEL_23\": 23,\n",
      "    \"LABEL_24\": 24,\n",
      "    \"LABEL_25\": 25,\n",
      "    \"LABEL_26\": 26,\n",
      "    \"LABEL_27\": 27,\n",
      "    \"LABEL_28\": 28,\n",
      "    \"LABEL_29\": 29,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_30\": 30,\n",
      "    \"LABEL_31\": 31,\n",
      "    \"LABEL_32\": 32,\n",
      "    \"LABEL_33\": 33,\n",
      "    \"LABEL_34\": 34,\n",
      "    \"LABEL_35\": 35,\n",
      "    \"LABEL_36\": 36,\n",
      "    \"LABEL_37\": 37,\n",
      "    \"LABEL_38\": 38,\n",
      "    \"LABEL_39\": 39,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_40\": 40,\n",
      "    \"LABEL_41\": 41,\n",
      "    \"LABEL_42\": 42,\n",
      "    \"LABEL_43\": 43,\n",
      "    \"LABEL_44\": 44,\n",
      "    \"LABEL_45\": 45,\n",
      "    \"LABEL_46\": 46,\n",
      "    \"LABEL_47\": 47,\n",
      "    \"LABEL_48\": 48,\n",
      "    \"LABEL_49\": 49,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_50\": 50,\n",
      "    \"LABEL_51\": 51,\n",
      "    \"LABEL_52\": 52,\n",
      "    \"LABEL_53\": 53,\n",
      "    \"LABEL_54\": 54,\n",
      "    \"LABEL_55\": 55,\n",
      "    \"LABEL_56\": 56,\n",
      "    \"LABEL_57\": 57,\n",
      "    \"LABEL_58\": 58,\n",
      "    \"LABEL_59\": 59,\n",
      "    \"LABEL_6\": 6,\n",
      "    \"LABEL_60\": 60,\n",
      "    \"LABEL_61\": 61,\n",
      "    \"LABEL_62\": 62,\n",
      "    \"LABEL_63\": 63,\n",
      "    \"LABEL_64\": 64,\n",
      "    \"LABEL_65\": 65,\n",
      "    \"LABEL_7\": 7,\n",
      "    \"LABEL_8\": 8,\n",
      "    \"LABEL_9\": 9\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 64,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 5,\n",
      "  \"num_hidden_layers\": 3,\n",
      "  \"pad_token_id\": 2,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.21.3\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 2291\n",
      "}\n",
      "\n",
      "loading weights file ../models/full-flat-1-finetune-0.0wd-0.25itps-it2/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing RobertaForTokenClassification.\n",
      "\n",
      "All the weights of RobertaForTokenClassification were initialized from the model checkpoint at ../models/full-flat-1-finetune-0.0wd-0.25itps-it2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForTokenClassification for predictions without further training.\n",
      "PyTorch: setting up devices\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForTokenClassification.forward` and have been ignored: translation, glosses, transcription, morphemes, segmentation. If translation, glosses, transcription, morphemes, segmentation are not expected by `RobertaForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2128\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating trainer...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDS [[61  1 46 ... 39 39 39]\n",
      " [54  1 25 ... 43 43 43]\n",
      " [38  1 53 ... 43 43 43]\n",
      " ...\n",
      " [30 32  1 ... 39 39 39]\n",
      " [38  1 42 ... 43 43 43]\n",
      " [61  1 30 ... 43 43 43]]\n",
      "LABELS [[  61    1   46 ... -100 -100 -100]\n",
      " [  54    1   25 ... -100 -100 -100]\n",
      " [  38    1   53 ... -100 -100 -100]\n",
      " ...\n",
      " [  30   32    1 ... -100 -100 -100]\n",
      " [  38    1   42 ... -100 -100 -100]\n",
      " [  61    1   30 ... -100 -100 -100]]\n",
      "(2128, 64)\n",
      "Preds:\t ['CONJ', '[SEP]', 'VOC', '[SEP]', 'CONJ', '[SEP]', 'VOC']\n",
      "Labels:\t ['CONJ', '[SEP]', 'VOC', '[SEP]', 'CONJ', '[SEP]', 'VOC']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.385240763425827,\n",
       " 'eval_average_accuracy': 0.8478330251606818,\n",
       " 'eval_accuracy': 0.8601065547303842,\n",
       " 'eval_runtime': 3.2271,\n",
       " 'eval_samples_per_second': 659.424,\n",
       " 'eval_steps_per_second': 10.536}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForTokenClassification\n",
    "from finetune_token_classifier import create_trainer\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"../models/full-flat-1-finetune-0.0wd-0.25itps-it2\")\n",
    "\n",
    "trainer = create_trainer(model, dataset=dataset, tokenizer=tokenizer, labels=glosses, batch_size=BATCH_SIZE,\n",
    "                         max_epochs=300, weight_decay=0, report_to='wandb')\n",
    "\n",
    "trainer.evaluate(dataset[\"dev\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "34f02f04-fe26-4fee-8a9d-b3b97801363a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForTokenClassification.forward` and have been ignored: translation, glosses, transcription, morphemes, segmentation. If translation, glosses, transcription, morphemes, segmentation are not expected by `RobertaForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2128\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDS [[46  1 54 ... 39 39 39]\n",
      " [54  1 56 ... 39 39 39]\n",
      " [54 62  1 ... 39 39 39]\n",
      " ...\n",
      " [38 43 43 ... 43 43 43]\n",
      " [39 32  1 ... 43 43 43]\n",
      " [26 38  1 ... 39 39 39]]\n",
      "LABELS [[  46    1   54 ... -100 -100 -100]\n",
      " [  54    1   57 ... -100 -100 -100]\n",
      " [  54   34    1 ... -100 -100 -100]\n",
      " ...\n",
      " [  38 -100 -100 ... -100 -100 -100]\n",
      " [  38   61    1 ... -100 -100 -100]\n",
      " [  26   39    1 ... -100 -100 -100]]\n",
      "(2128, 64)\n",
      "Preds:\t ['VOC', '[SEP]', 'ADV', '[SEP]', 'DEM']\n",
      "Labels:\t ['VOC', '[SEP]', 'ADV', '[SEP]', 'DEM']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.7491924166679382,\n",
       " 'eval_average_accuracy': 0.7587232684322329,\n",
       " 'eval_accuracy': 0.761578415813014,\n",
       " 'eval_runtime': 3.2315,\n",
       " 'eval_samples_per_second': 658.527,\n",
       " 'eval_steps_per_second': 10.522}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(dataset[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a9da506-5a8b-49d7-939c-b9117d167361",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "967c4b03c4fc4c1c8a4c5d3e34ab601b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2128 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set don't have a corresponding argument in `RobertaForTokenClassification.forward` and have been ignored: translation, glosses, transcription, morphemes, segmentation. If translation, glosses, transcription, morphemes, segmentation are not expected by `RobertaForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 2128\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDS [[56  1 65 ... 43 43 43]\n",
      " [54  1 26 ... 39 39 39]\n",
      " [39  1 25 ... 43 43 43]\n",
      " ...\n",
      " [26 38 14 ... 43 43 43]\n",
      " [25 39  1 ... 39 39 39]\n",
      " [41  1 26 ... 39 39 39]]\n",
      "LABELS [[  56    1   65 ... -100 -100 -100]\n",
      " [  54    1   26 ... -100 -100 -100]\n",
      " [  39    1   25 ... -100 -100 -100]\n",
      " ...\n",
      " [  26   39   34 ... -100 -100 -100]\n",
      " [  25   39    1 ... -100 -100 -100]\n",
      " [  54    1   26 ... -100 -100 -100]]\n",
      "(2128, 64)\n",
      "Preds:\t ['NEG', '[SEP]', 'PREP']\n",
      "Labels:\t ['NEG', '[SEP]', 'PREP']\n"
     ]
    }
   ],
   "source": [
    "# Write predictions\n",
    "from data_handling import write_predictions\n",
    "\n",
    "write_predictions(eval_ood, tokenizer, trainer, glosses, '../data/GenBench/pred_eval_ood_0.25_it2.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9614e4f0-69aa-4fd5-8753-ef32eb54e417",
   "metadata": {},
   "source": [
    "## Denoiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "04bffa59-8b4a-4b95-99c2-312a791c1eae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set don't have a corresponding argument in `RobertaForTokenClassification.forward` and have been ignored: translation, glosses, transcription, morphemes, segmentation. If translation, glosses, transcription, morphemes, segmentation are not expected by `RobertaForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 2128\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDS [[46  1 54 ... 39 39 39]\n",
      " [54  1 56 ... 39 39 39]\n",
      " [54 62  1 ... 39 39 39]\n",
      " ...\n",
      " [38 43 43 ... 43 43 43]\n",
      " [39 32  1 ... 43 43 43]\n",
      " [26 38  1 ... 39 39 39]]\n",
      "LABELS [[  46    1   54 ... -100 -100 -100]\n",
      " [  54    1   57 ... -100 -100 -100]\n",
      " [  54   34    1 ... -100 -100 -100]\n",
      " ...\n",
      " [  38 -100 -100 ... -100 -100 -100]\n",
      " [  38   61    1 ... -100 -100 -100]\n",
      " [  26   39    1 ... -100 -100 -100]]\n",
      "(2128, 64)\n",
      "Preds:\t ['VOC', '[SEP]', 'ADV', '[SEP]', 'DEM']\n",
      "Labels:\t ['VOC', '[SEP]', 'ADV', '[SEP]', 'DEM']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file ../models/usp-gloss-denoiser-micro/config.json\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"../models/usp-gloss-denoiser-micro\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 100,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 64,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 5,\n",
      "  \"num_hidden_layers\": 3,\n",
      "  \"pad_token_id\": 2,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.21.3\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 70\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1327 total unknown tokens, 1056 wrong = 0.7957799547852299\n",
      "12535 total known tokens, 2249 wrong = 0.17941763063422417\n",
      "3305 total wrong of 13862 total tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file ../models/usp-gloss-denoiser-micro/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing RobertaForMaskedLM.\n",
      "\n",
      "All the weights of RobertaForMaskedLM were initialized from the model checkpoint at ../models/usp-gloss-denoiser-micro.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForMaskedLM for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39ebd0a631fd4f0bbf564ba265e8dbb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/990 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "459/1327 unknown from 271, with 228 shared\n",
      "Perf on unknown: 0.20422004521477016 before, 0.3458929917106255 after\n",
      "0.013562256528639446 improvement in accuracy.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "target_set = dataset[\"test\"]\n",
    "\n",
    "unknown_tokens = 0\n",
    "unknown_token_wrong = 0\n",
    "known_tokens = 0\n",
    "known_token_wrong = 0\n",
    "\n",
    "preds = trainer.predict(target_set)\n",
    "\n",
    "rows_with_unknowns = set()\n",
    "\n",
    "for row_index, row in enumerate(target_set):\n",
    "    for pos in range(len(row['input_ids'])):\n",
    "        if row['input_ids'][pos] == 2:\n",
    "            break\n",
    "        if row['input_ids'][pos] == 1:\n",
    "            continue\n",
    "        \n",
    "        if row['input_ids'][pos] == 0:\n",
    "            unknown_tokens += 1\n",
    "            rows_with_unknowns.add(row_index)\n",
    "\n",
    "            if preds.predictions[row_index][pos] != row['labels'][pos]:\n",
    "                # Incorrect\n",
    "                unknown_token_wrong += 1\n",
    "        else:\n",
    "            known_tokens += 1\n",
    "            if preds.predictions[row_index][pos] != row['labels'][pos]:\n",
    "                # Incorrect\n",
    "                known_token_wrong += 1\n",
    "                \n",
    "print(f\"{unknown_tokens} total unknown tokens, {unknown_token_wrong} wrong = {unknown_token_wrong / unknown_tokens}\")\n",
    "print(f\"{known_tokens} total known tokens, {known_token_wrong} wrong = {known_token_wrong / known_tokens}\")\n",
    "print(f\"{unknown_token_wrong + known_token_wrong} total wrong of {known_tokens + unknown_tokens} total tokens\")\n",
    "\n",
    "total_correct_before = 0\n",
    "total_fixed = 0\n",
    "both_correct = 0\n",
    "total = 0\n",
    "\n",
    "denoiser = AutoModelForMaskedLM.from_pretrained(\"../models/usp-gloss-denoiser-micro\")\n",
    "\n",
    "for row_id in tqdm(rows_with_unknowns):\n",
    "    test_row = target_set[row_id]\n",
    "    test_preds = torch.LongTensor([preds.predictions[row_id]])\n",
    "    input_ids = torch.LongTensor([test_row['input_ids']])\n",
    "    labels = torch.LongTensor([test_row['labels']])\n",
    "\n",
    "    test_preds[test_preds != 1] = test_preds[test_preds != 1] + 4\n",
    "\n",
    "    # test_preds[input_ids == 0] = 3 # MASK unknown word\n",
    "    test_preds = test_preds.narrow(-1, 0, 60)\n",
    "\n",
    "    attention_mask = torch.LongTensor([test_row['attention_mask']])\n",
    "    attention_mask = attention_mask.narrow(-1, 0, 60)\n",
    "\n",
    "    denoised_preds = denoiser.forward(input_ids=test_preds, attention_mask=attention_mask).logits.argmax(dim=2)\n",
    "    \n",
    "    for pos in range(len(test_row['input_ids'])):\n",
    "        if test_row['input_ids'][pos] == 2:\n",
    "            break\n",
    "        if test_row['input_ids'][pos] == 1:\n",
    "            continue\n",
    "        if test_row['input_ids'][pos] == 0:\n",
    "            total += 1\n",
    "            prior_correct = preds.predictions[row_id][pos] == test_row['labels'][pos]\n",
    "            post_correct = denoised_preds[0][pos] - 4 == test_row['labels'][pos]\n",
    "            if prior_correct:\n",
    "                total_correct_before += 1\n",
    "            if post_correct:\n",
    "                total_fixed += 1\n",
    "            if prior_correct and post_correct:\n",
    "                both_correct += 1\n",
    "\n",
    "    # correct = denoised_preds[input_ids.narrow(-1, 0, 60) == 0] - 4 == labels[input_ids == 0]\n",
    "    # correct = correct.long()\n",
    "    # total_fixed += torch.sum(correct)\n",
    "    \n",
    "print(f\"{total_fixed}/{total} unknown from {total_correct_before}, with {both_correct} shared\")\n",
    "print(f\"Perf on unknown: {total_correct_before / total} before, {total_fixed / total} after\")\n",
    "\n",
    "improved_tokens = total_fixed - total_correct_before\n",
    "acc_improvement = improved_tokens / (known_tokens + unknown_tokens)\n",
    "print(f\"{acc_improvement} improvement in accuracy.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34587dfa-c73a-45f0-9ed2-320c5508bf88",
   "metadata": {},
   "source": [
    "# Iterative Pseudo-Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ba68ffbf-6cca-47cc-ba75-9260a6b36afc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e98578dd657459cac7fb78af3440fdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/532 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForTokenClassification.forward` and have been ignored: translation, glosses, transcription, morphemes, segmentation. If translation, glosses, transcription, morphemes, segmentation are not expected by `RobertaForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 532\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDS [[56  1 65 ... 43 43 43]\n",
      " [54  1 26 ... 39 39 39]\n",
      " [54  1 43 ... 39 39 39]\n",
      " ...\n",
      " [60  1 57 ... 39 39 39]\n",
      " [43  1 57 ... 43 43 43]\n",
      " [54  1 25 ... 39 39 39]]\n",
      "LABELS [[  56    1   65 ... -100 -100 -100]\n",
      " [  54    1   26 ... -100 -100 -100]\n",
      " [  54    1   39 ... -100 -100 -100]\n",
      " ...\n",
      " [  60    1   57 ... -100 -100 -100]\n",
      " [  43    1   57 ... -100 -100 -100]\n",
      " [  54    1   25 ... -100 -100 -100]]\n",
      "(532, 64)\n",
      "Preds:\t ['NEG', '[SEP]', 'PREP']\n",
      "Labels:\t ['NEG', '[SEP]', 'PREP']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.4851396679878235,\n",
       " 'eval_average_accuracy': 0.8771882305246967,\n",
       " 'eval_accuracy': 0.8665610142630745,\n",
       " 'eval_runtime': 0.8268,\n",
       " 'eval_samples_per_second': 643.456,\n",
       " 'eval_steps_per_second': 10.886}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "target_set = dataset[\"test\"]\n",
    "target_data = test_ood\n",
    "\n",
    "logits = model.forward(input_ids=torch.LongTensor(target_set['input_ids']), attention_mask=torch.LongTensor(target_set['attention_mask'])).logits\n",
    "\n",
    "row_confidences = []\n",
    "\n",
    "# For each sequence, pick the top logit for each token and average log probs\n",
    "for index in range(len(target_set)):\n",
    "    row = target_set[index]\n",
    "    row_logits = logits[index] # 64 * 66\n",
    "    \n",
    "    num_tokens = len(row['morphemes'])\n",
    "    row_logits_sum = 0\n",
    "    \n",
    "    for token_index in range(num_tokens):\n",
    "        token_logits = row_logits[token_index]\n",
    "        token_logits = F.softmax(token_logits, dim=0)\n",
    "        max_token_logit = torch.max(token_logits).item()\n",
    "        row_logits_sum += max_token_logit\n",
    "    \n",
    "    avg_prob = row_logits_sum / num_tokens\n",
    "    row_confidences.append(avg_prob)\n",
    "    \n",
    "top_indices = sorted(range(len(row_confidences)), key=lambda x: row_confidences[x])[-int(len(row_confidences) / 4):]\n",
    "\n",
    "dataset['hiconf_dev'] = prepare_dataset(data=[target_data[i] for i in range(len(eval_ood)) if i in top_indices], tokenizer=tokenizer, labels=glosses, device=device)\n",
    "trainer.evaluate(dataset['hiconf_dev'])\n",
    "\n",
    "write_predictions([eval_ood[i] for i in range(len(target_data)) if i in top_indices], tokenizer, trainer, glosses, '../data/GenBench/pred_eval_ood_0.25_it3.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d10d95-1a37-4814-880f-102f1f877913",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
